[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Your Name",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nSumedh Hambarde\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\nSumedh Hambarde\nMay 7, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\nFundraisers often rely on rules of thumb rather than scientific evidence to guide their strategies. While the economics of charity has been studied from the “supply” side (e.g., the impact of tax deductions), there are still “critical gaps” in understanding the “demand” side (i.e., how and why donors choose to give).  \nOne common fundraising tool is the matching grant, where a donor pledges to match the contributions of others. Fundraisers often believe that higher matching ratios (e.g., 2:1 or 3:1) are more effective in attracting donations, but there is limited research to support this.\n\n\n\nKarlan and List (2007) aimed to address this gap by examining the impact of matching grants on charitable giving through a large-scale natural field experiment. Specifically, the study investigates whether and to what extent “price” (in the form of matching grant ratios) matters in charitable fundraising.  \n\n\n\nThe experiment was conducted in collaboration with a liberal non-profit organization in the United States that focuses on social and policy issues related to civil liberties. The organization is a 501(c)3 charity, meaning donations are tax-deductible. The organization regularly solicits donations from its prior donors through direct mail campaigns.  \nThe organization’s membership has the following characteristics:\n\nApproximately 70% male\nApproximately 60% over 65 years old\nApproximately 80% with a college education\nPolitical leaning: 85% voted for Gore in the 2000 presidential election\n\n\n\n\nThe researchers conducted a natural field experiment using a direct mail solicitation to over 50,000 past donors of the organization. Individuals were randomly assigned to either a treatment group that received a matching grant offer or a control group that did not. The treatment group was further randomized to receive different matching grant ratios.\n\n\n\nAll participants received a four-page fundraising letter.  \nControl Group: Received a standard letter with no mention of a matching grant.   Treatment Groups: Received a letter that included an additional paragraph announcing the matching grant offer. The matching grant had different price ratios: 1:1 match: For every dollar donated, the organization receives two dollars.   2:1 match: For every dollar donated, the organization receives three dollars.   3:1 match: For every dollar donated, the organization receives four dollars."
  },
  {
    "objectID": "projects/project1/index.html#introduction",
    "href": "projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\nFundraisers often rely on rules of thumb rather than scientific evidence to guide their strategies. While the economics of charity has been studied from the “supply” side (e.g., the impact of tax deductions), there are still “critical gaps” in understanding the “demand” side (i.e., how and why donors choose to give).  \nOne common fundraising tool is the matching grant, where a donor pledges to match the contributions of others. Fundraisers often believe that higher matching ratios (e.g., 2:1 or 3:1) are more effective in attracting donations, but there is limited research to support this.\n\n\n\nKarlan and List (2007) aimed to address this gap by examining the impact of matching grants on charitable giving through a large-scale natural field experiment. Specifically, the study investigates whether and to what extent “price” (in the form of matching grant ratios) matters in charitable fundraising.  \n\n\n\nThe experiment was conducted in collaboration with a liberal non-profit organization in the United States that focuses on social and policy issues related to civil liberties. The organization is a 501(c)3 charity, meaning donations are tax-deductible. The organization regularly solicits donations from its prior donors through direct mail campaigns.  \nThe organization’s membership has the following characteristics:\n\nApproximately 70% male\nApproximately 60% over 65 years old\nApproximately 80% with a college education\nPolitical leaning: 85% voted for Gore in the 2000 presidential election\n\n\n\n\nThe researchers conducted a natural field experiment using a direct mail solicitation to over 50,000 past donors of the organization. Individuals were randomly assigned to either a treatment group that received a matching grant offer or a control group that did not. The treatment group was further randomized to receive different matching grant ratios.\n\n\n\nAll participants received a four-page fundraising letter.  \nControl Group: Received a standard letter with no mention of a matching grant.   Treatment Groups: Received a letter that included an additional paragraph announcing the matching grant offer. The matching grant had different price ratios: 1:1 match: For every dollar donated, the organization receives two dollars.   2:1 match: For every dollar donated, the organization receives three dollars.   3:1 match: For every dollar donated, the organization receives four dollars."
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nimport pandas as pd\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n#print(data.head())\n\nprint(data.info())\n\nprint(data.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168560      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378105     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258633  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\n\nBalance Tests: Checking the success of randomization\nIn any experiment that uses random assignment, it’s crucial to verify that the randomization process was successful in creating comparable groups. This ensures that any differences I observe in donation behavior are likely due to the matching grant offers and not simply due to pre-existing differences between the groups. To do this, I conducted balance tests on several pre-treatment variables.\n\nMethodology\nTo assess the balance between the treatment and control groups, I performed two types of statistical tests for each pre-treatment variable:\n\nT-tests: I used independent samples t-tests to compare the means of each variable between the treatment and control groups. The null hypothesis for each t-test was that there is no difference in the average value of the variable between the two groups.\nLinear Regressions: I also ran a series of simple linear regressions. In each regression, the pre-treatment variable was the dependent variable, and the treatment assignment (coded as 0 for control and 1 for treatment) was the independent variable. This allowed me to estimate the average difference in the pre-treatment variable between the treatment and control groups.\n\nIt’s important to note that, as the professor emphasized, the t-test and the regression approach are two ways of examining the same thing and should give me very similar results.\n\n\nResults\nI conducted these balance tests on the following pre-treatment variables:\n\nMonths since last donation\nNumber of prior donations\nFemale (an indicator variable for gender)\nCouple (an indicator variable for whether the individual is part of a couple)\n\nThe code for this, as well as the results from the balance tests are as follows:\n\nimport pandas as pd\nfrom scipy import stats\nimport statsmodels.formula.api as sm\nimport numpy as np\n\n# Load your data\ndata = pd.read_stata('dataverse_files/AER merged.dta')  # Or pd.read_csv(), etc.\n\n#print(data[['treatment', 'control']].head(2))\ndef test_balance(var_value, var_name):\n\n    print('\\n')\n    variable_to_test = var_value\n\n    # T-test\n    control_group = data[data['control'] == 1][variable_to_test]\n    treatment_group = data[data['treatment'] == 1][variable_to_test]\n    #print(treatment_group.head(2))\n    #print(control_group.head(2))\n\n    # Calculate means\n    mean_control = np.mean(control_group)\n    mean_treatment = np.mean(treatment_group)\n\n    # Calculate variances\n    variance_control = np.var(control_group, ddof=1)  # ddof=1 for sample variance\n    variance_treatment = np.var(treatment_group, ddof=1)\n\n    # Calculate sample sizes\n    n_control = len(control_group)\n    n_treatment = len(treatment_group)\n\n    # Calculate pooled variance\n    pooled_variance = ((n_treatment - 1) * variance_treatment + (n_control - 1) * variance_control) / (n_treatment + n_control - 2)\n\n    # Calculate pooled standard error\n    pooled_standard_error = np.sqrt(pooled_variance * (1 / n_treatment + 1 / n_control))\n\n    # Calculate t-statistic\n    t_statistic_manual = (mean_treatment - mean_control) / pooled_standard_error\n    print(f\"t-statistic for {var_name}: t = {t_statistic_manual:.3f}\")\n\n    df = n_treatment + n_control - 2\n\n    p_value_manual_two_tailed = stats.t.sf(abs(t_statistic_manual), df) * 2\n\n    print(f\"Two-Tailed p-value: {p_value_manual_two_tailed:.3f}\")\n\n\n\n    # Linear Regression\n    formula = f'{variable_to_test} ~ treatment'\n    model = sm.ols(formula, data=data).fit()\n    p_value_reg = model.pvalues['treatment']\n    print(f\"Regression for {var_name}: p = {p_value_reg:.3f}\")\n\n    # Interpretation\n    if p_value_manual_two_tailed &lt; 0.05:\n        print(f\"For {var_name}, there is a statistically significant difference between treatment and control groups.\")\n    else:\n        print(f\"For {var_name}, there is no statistically significant difference between treatment and control groups.\")\n\n\ntest_balance('mrm2', 'Months since last donation')\ntest_balance('freq', 'Number of Prior Donations')\n#test_balance('perbush', 'State vote share for Bush')\n#test_balance('cases', 'Court cases from 2004-05 in which organization was involved')\ntest_balance('female', 'Female')\ntest_balance('couple', 'Couple')\n# Repeat for other variables\n\n\n\nt-statistic for Months since last donation: t = 0.119\nTwo-Tailed p-value: 0.905\nRegression for Months since last donation: p = 0.905\nFor Months since last donation, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Number of Prior Donations: t = -0.111\nTwo-Tailed p-value: 0.912\nRegression for Number of Prior Donations: p = 0.912\nFor Number of Prior Donations, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Female: t = -1.778\nTwo-Tailed p-value: 0.075\nRegression for Female: p = 0.079\nFor Female, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Couple: t = -0.590\nTwo-Tailed p-value: 0.555\nRegression for Couple: p = 0.559\nFor Couple, there is no statistically significant difference between treatment and control groups.\n\n\n\n\nOverall Assessment of Randomization\nBased on these balance tests, I conclude that the randomization process in the Karlan and List (2007) experiment appears to have been largely successful. For all four pre-treatment variables I examined, I did not find statistically significant differences between the treatment and control groups at the 0.05 significance level.\nWhile some minor differences are expected due to chance, especially in large samples, the general lack of statistical significance suggests that the treatment and control groups are indeed comparable. This strengthens the internal validity of the study and supports the authors’ ability to attribute any observed differences in donation behavior to the matching grant offers.\n\n\nImportance of Balance Tests\nBalance tests are a critical component of any experimental study, and Karlan and List (2007) included them for good reason. These tests serve several important purposes:\n\nEstablishing Internal Validity: They provide evidence that the treatment, rather than pre-existing differences, is the likely cause of any observed effects.\nSupporting Causal Inference: They justify making causal claims about the impact of the treatment.\nEnsuring Rigor: They demonstrate the rigor of the experimental design and increase confidence in the study’s findings.\nPromoting Transparency: They allow other researchers to assess the quality of the experiment and attempt to replicate the results."
  },
  {
    "objectID": "projects/project1/index.html#experimental-results",
    "href": "projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot for proportion of people who donated\n\nimport pandas as pd\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\nimport plotly.graph_objects as go\n\ndef plot_donation_by_group(data):\n    # 2. Calculate donation proportions\n    proportion_gave_treatment = data[data['treatment'] == 1]['gave'].mean()\n    proportion_gave_control = data[data['control'] == 1]['gave'].mean()\n\n    # 3. Prepare data for plotting\n    plot_data = pd.DataFrame({\n        'group': ['Treatment', 'Control'],\n        'proportion_gave': [proportion_gave_treatment, proportion_gave_control]\n    })\n\n    # 4. Create the bar plot\n    fig = go.Figure(data=[\n        go.Bar(x=plot_data['group'], y=plot_data['proportion_gave'])\n    ])\n\n    fig.add_trace(go.Scatter(\n        x=plot_data['group'],\n        y=plot_data['proportion_gave'],\n        text=[f\"{100 * p:.2f}%\" for p in plot_data['proportion_gave']],  # Format proportions\n        mode='text',\n        textposition='top center'\n    ))\n    # 5. Customize the plot\n    fig.update_layout(\n        title='Proportion of Donors by Group',\n        xaxis_title='Group',\n        yaxis_title='Proportion Donated',\n        yaxis_range=[0, max(plot_data['proportion_gave']) * 1.1]  # Extend y-axis slightly\n    )\n\n    # 6. Display the plot\n    fig.show()\n\n\nplot_donation_by_group(data)\n\n                                                \n\n\nThe results of my analysis show that the treatment group, which received the matching grant offer, had a higher donation rate (2.2%) compared to the control group (1.79%). This suggests that the matching grant may have had a positive impact on the likelihood of individuals making a donation. However, it’s important to keep in mind that this is just a preliminary observation, and further statistical testing is needed to determine if this difference is statistically significant.\n\n\nBinary donation outcome: t-test and it’s interpretation:\n\nimport pandas as pd\nfrom scipy import stats  # For t-test\n\ndef perform_t_test_on_donation(data):\n    \"\"\"\n    Performs an independent samples t-test on the binary donation outcome.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'treatment', 'control', and 'gave' columns.\n\n    Returns:\n        tuple: (t-statistic, p-value)\n    \"\"\"\n    # --- T-test ---\n    treatment_gave = data[data['treatment'] == 1]['gave']\n    control_gave = data[data['control'] == 1]['gave']\n    t_statistic, p_value_ttest = stats.ttest_ind(treatment_gave, control_gave)\n\n    return t_statistic, p_value_ttest\n\n\nif __name__ == '__main__':\n    # --- Load Your Actual Data Here ---\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with your data loading\n\n    t_statistic, p_value = perform_t_test_on_donation(data)\n\n    print(\"--- T-test Results ---\")\n    print(f\"T-statistic: {t_statistic:.3f}\")\n    print(f\"P-value: {p_value:.3f}\")\n\n    # You would then proceed to interpret these results\n\n--- T-test Results ---\nT-statistic: 3.101\nP-value: 0.002\n\n\n\n\nInterpretation of the t-test:\nThe t-test results indicate a statistically significant difference in donation behavior between the group that received the matching grant offer (the treatment group) and the group that did not (the control group). The p-value of 0.002 is substantially lower than the typical significance level of 0.05, meaning that the observed difference is unlikely to have occurred by chance alone. In other words, there’s strong evidence to suggest that the matching grant offer had a real effect on whether people decided to donate.\nThe positive t-statistic (3.101) suggests that the treatment group had a higher donation rate. This finding aligns with the idea that individuals respond to price-like incentives, even in charitable giving. The matching grant effectively reduces the ‘cost’ of giving; for every dollar a person donates, the charity receives more. This increased ‘bang for your buck’ appears to motivate people to be more generous.\nFrom a behavioral perspective, this result highlights that while altruism and a desire to support a cause are important motivators for charitable giving, financial incentives can also play a significant role. People seem to weigh the perceived value of their contribution, and matching grants can significantly shift that calculation. This underscores the potential effectiveness of matching grant campaigns as a fundraising strategy.\n\n\nProbit regression: Results and interpretation\n\nimport pandas as pd\nimport statsmodels.api as sm  # For Probit regression\n\ndef perform_probit_regression(data):\n    \"\"\"\n    Performs a probit regression to model the probability of donation.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'treatment', 'control', and 'gave' columns.\n\n    Returns:\n        sm.ProbitResults: The results of the probit regression.\n    \"\"\"\n\n    # --- Verify that 'treatment' and 'control' are mutually exclusive ---\n    # --- Create treatment dummy variable ---\n    data['treatment_dummy'] = data['treatment']  # Assuming 'treatment' is 1/0\n\n    # --- Probit Regression ---\n    formula = 'gave ~ treatment_dummy'\n    probit_model = sm.Probit(data['gave'], sm.add_constant(data['treatment_dummy']))\n    probit_results = probit_model.fit()\n\n    return probit_results\n\n\nif __name__ == '__main__':\n    data = pd.read_stata('dataverse_files/AER merged.dta')\n    probit_results = perform_probit_regression(data)\n    \n    # --- Print Results Summary ---\n    print(probit_results.summary())\n\n    # --- Access specific results ---\n    print(\"\\nProbit Regression Results:\")\n    print(f\"Coefficient on treatment: {probit_results.params['treatment_dummy']:.4f}\")\n    print(f\"P-value on treatment: {probit_results.pvalues['treatment_dummy']:.4f}\")\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Fri, 25 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        02:12:18   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n===================================================================================\n                      coef    std err          z      P&gt;|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nconst              -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment_dummy     0.0868      0.028      3.113      0.002       0.032       0.141\n===================================================================================\n\nProbit Regression Results:\nCoefficient on treatment: 0.0868\nP-value on treatment: 0.0019\n\n\n\n\nInterpretation of the results:\nThe probit regression results indicate a statistically significant positive effect of the matching grant offer on the probability of making a charitable donation. The coefficient on the treatment_dummy variable is 0.0868, and it has a p-value of 0.002, which is well below the conventional significance level of 0.05. This suggests that being offered a matching grant significantly increased the likelihood that an individual would donate.\nTo understand the magnitude of this effect, we need to consider that the coefficients in a probit regression represent the change in the z-score of the standard normal distribution associated with a one-unit change in the predictor variable (in this case, going from the control group to the treatment group). While the coefficient itself isn’t a direct measure of the change in probability, its positive and statistically significant value clearly demonstrates that the matching offer had a positive impact on the propensity to give.\nIn behavioral terms, this finding reinforces the idea that the ‘price’ mechanism introduced by the matching grant influences donation decisions. The offer of having their donation matched appears to have provided an additional incentive, nudging individuals who received the treatment letter towards donating at a higher rate than those in the control group who did not receive such an offer. This aligns with economic theories suggesting that individuals respond to incentives, even in the realm of altruistic behavior.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\nPairwise t-tests: Results\n\nimport pandas as pd\nfrom scipy import stats  # For t-test\n\ndef compare_donation_rates_by_ratio(data):\n    \"\"\"\n    Compares donation rates across different match ratios using t-tests.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'ratio' and 'gave' columns.\n\n    Returns:\n        dict: A dictionary containing the t-test results for each comparison.\n    \"\"\"\n\n    results = {}\n\n    # 1:1 vs. 2:1\n    gave_1 = data[data['ratio'] == 1]['gave']\n    gave_2 = data[data['ratio'] == 2]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_1, gave_2)\n    results['1:1 vs. 2:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    # 1:1 vs. 3:1\n    gave_1 = data[data['ratio'] == 1]['gave']\n    gave_3 = data[data['ratio'] == 3]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_1, gave_3)\n    results['1:1 vs. 3:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    # 2:1 vs. 3:1\n    gave_2 = data[data['ratio'] == 2]['gave']\n    gave_3 = data[data['ratio'] == 3]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_2, gave_3)\n    results['2:1 vs. 3:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    return results\n\n\nif __name__ == '__main__':\n    # --- Load Your Actual Data Here ---\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with your data loading\n\n    results = compare_donation_rates_by_ratio(data)\n\n    # --- Print Results ---\n    print(\"T-test Results: Donation Rates by Match Ratio\")\n    for comparison, values in results.items():\n        print(f\"\\nComparison: {comparison}\")\n        print(f\"  T-statistic: {values['t_statistic']:.3f}\")\n        print(f\"  P-value: {values['p_value']:.3f}\")\n\nT-test Results: Donation Rates by Match Ratio\n\nComparison: 1:1 vs. 2:1\n  T-statistic: -0.965\n  P-value: 0.335\n\nComparison: 1:1 vs. 3:1\n  T-statistic: -1.015\n  P-value: 0.310\n\nComparison: 2:1 vs. 3:1\n  T-statistic: -0.050\n  P-value: 0.960\n\n\n\n\nPairwise t-tests: Interpretation:\nLack of Statistical Significance:\n\nFor all three comparisons, the p-values are considerably greater than the common significance level of 0.05.\nThis means that we fail to reject the null hypothesis in each case. The null hypothesis states that there is no difference in the average donation rates between the two groups being compared.\nIn simpler terms, the data does not provide enough evidence to conclude that changing the match ratio (from 1:1 to 2:1, from 1:1 to 3:1, or from 2:1 to 3:1) has a statistically significant impact on the proportion of people who donate.\nThese results match the conclusions made in the original research publication.\n\nBehavioral Implications:\n\nThese findings might suggest that, within the range of match ratios tested, the specific generosity of the match offer doesn’t strongly influence the likelihood of donating.\nIt’s possible that the presence of any match is more important than the size of the match. People might be motivated by the simple fact that their donation will be multiplied, without being very sensitive to the exact multiplication factor.\nAnother possibility is that the differences in match ratios tested were not large enough to elicit a statistically detectable change in behavior.\n\n\nimport statsmodels.formula.api as sm  # For OLS regression\n\nimport pandas as pd\ndata = pd.read_stata('dataverse_files/AER merged.dta')\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\n# --- Regression ---\nformula = 'gave ~ ratio1 + ratio2 + ratio3'\nmodel = sm.ols(formula, data=data).fit()\n\n# --- Print Results Summary ---\nprint(model.summary())\n\n# --- Interpretation ---\nprint(\"\\nRegression Results Interpretation:\")\nprint(\"----------------------------\")\n\nprint(f\"Coefficient for ratio1: {model.params['ratio1']:.4f}\")\nprint(f\"P-value for ratio1: {model.pvalues['ratio1']:.4f}\")\n\nprint(f\"Coefficient for ratio2: {model.params['ratio2']:.4f}\")\nprint(f\"P-value for ratio2: {model.pvalues['ratio2']:.4f}\")\n\nprint(f\"Coefficient for ratio3: {model.params['ratio3']:.4f}\")\nprint(f\"P-value for ratio3: {model.pvalues['ratio3']:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Fri, 25 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        02:12:19   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nRegression Results Interpretation:\n----------------------------\nCoefficient for ratio1: 0.0029\nP-value for ratio1: 0.0966\nCoefficient for ratio2: 0.0048\nP-value for ratio2: 0.0061\nCoefficient for ratio3: 0.0049\nP-value for ratio3: 0.0051\n\n\nInterpretation of the OLS Regression Results\nIn this OLS regression, we modeled the binary outcome of whether a donation was made (gave) as a function of dummy variables representing the different match ratios (ratio1 for 1:1, ratio2 for 2:1, and ratio3 for 3:1). The “Control” group (no match) serves as the implicit reference category.\nHere’s a breakdown of the key findings:\nIntercept (Coefficient: 0.0179, P-value: 0.000): The intercept represents the predicted probability of donation for the reference group, which is the “Control” group (where ratio1, ratio2, and ratio3 are all 0). A coefficient of 0.0179 suggests that in the absence of any matching offer, the predicted donation rate is approximately 1.79%. This is statistically significant (p &lt; 0.001).\nCoefficient for ratio1 (0.0029, P-value: 0.097): This coefficient estimates the additional change in the probability of donation when the match ratio is 1:1, compared to the Control group. The positive coefficient (0.0029) suggests that the 1:1 match is associated with a 0.29 percentage point increase in the predicted donation rate (1.79% + 0.29% = 2.08%). However, the p-value of 0.097 is greater than the conventional significance level of 0.05. Therefore, we do not have statistically significant evidence that the 1:1 matching offer significantly increased donations compared to the control group in this OLS model.\nCoefficient for ratio2 (0.0048, P-value: 0.006): This coefficient estimates the additional change in the probability of donation when the match ratio is 2:1, compared to the Control group. The positive and statistically significant coefficient (0.0048, p = 0.006) indicates that the 2:1 matching offer led to a significant increase of 0.48 percentage points in the predicted donation rate compared to the Control group (1.79% + 0.48% = 2.27%).\nCoefficient for ratio3 (0.0049, P-value: 0.005): This coefficient estimates the additional change in the probability of donation when the match ratio is 3:1, compared to the Control group. The positive and statistically significant coefficient (0.0049, p = 0.005) shows that the 3:1 matching offer resulted in a significant increase of 0.49 percentage points in the predicted donation rate compared to the Control group (1.79% + 0.49% = 2.28%).\nOverall Interpretation:\nThe OLS regression results suggest that while a 1:1 matching offer did not significantly increase donation rates compared to no offer, both the 2:1 and 3:1 matching offers had a statistically significant positive impact on the likelihood of donation. The magnitudes of the effects for the 2:1 and 3:1 matches are quite similar, suggesting that increasing the match ratio beyond 2:1 might not lead to a substantial further increase in the proportion of donors.\nThese findings are broadly consistent with the idea that matching grants incentivize charitable giving. The stronger effects observed for the higher match ratios (2:1 and 3:1) provide some evidence that the “price” of giving matters, with a more generous match leading to a greater increase in donation propensity compared to no match. However, the lack of a significant effect for the 1:1 match hints at a possible threshold effect or a weaker influence at that particular ratio in this model.\n\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\ndef calculate_direct_response_rate_differences(data):\n    \"\"\"Calculates response rate differences directly from data.\"\"\"\n    prop_1 = data[data['ratio'] == 1]['gave'].mean()\n    prop_2 = data[data['ratio'] == 2]['gave'].mean()\n    prop_3 = data[data['ratio'] == 3]['gave'].mean()\n    return {\n        '1:1 vs. 2:1': prop_2 - prop_1,\n        '2:1 vs. 3:1': prop_3 - prop_2,\n        '1:1 vs. 3:1': prop_3 - prop_1  # Added comparison\n    }\n\ndef regress_and_get_coefficient_differences(data):\n    \"\"\"Regresses 'gave' on ratio dummies and returns coefficient differences.\"\"\"\n    formula = 'gave ~ ratio1 + ratio2 + ratio3'\n    model = sm.ols(formula, data=data).fit()\n    return {\n        '1:1 vs. 2:1': model.params['ratio2'] - model.params['ratio1'],\n        '2:1 vs. 3:1': model.params['ratio3'] - model.params['ratio2'],\n        '1:1 vs. 3:1': model.params['ratio3'] - model.params['ratio1']  # Added comparison\n    }\n\nif __name__ == '__main__':\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with actual data loading\n    data['ratio1'] = (data['ratio'] == 1).astype(int)\n    data['ratio2'] = (data['ratio'] == 2).astype(int)\n    data['ratio3'] = (data['ratio'] == 3).astype(int)\n\n    direct_diffs = calculate_direct_response_rate_differences(data)\n    regression_diffs = regress_and_get_coefficient_differences(data)\n\n    print(\"Response Rate Differences:\")\n    for key in direct_diffs:\n        print(f\"  {key}: Direct = {direct_diffs[key]:.4f}, Regression = {regression_diffs[key]:.4f}\")\n\n    # Interpretation\n    print(\"\\nInterpretation:\")\n    print(\"--------------------\")\n\n    # Example: Compare the direct and regression differences\n    print(\"Comparison of Direct and Regression Differences:\")\n    for key in direct_diffs:\n        print(f\"  {key}: Difference = {abs(direct_diffs[key] - regression_diffs[key]):.4f}\")\n\n    # Draw conclusions about effectiveness\n    # ... (Your conclusions here based on the compared differences)\n\nResponse Rate Differences:\n  1:1 vs. 2:1: Direct = 0.0019, Regression = 0.0019\n  2:1 vs. 3:1: Direct = 0.0001, Regression = 0.0001\n  1:1 vs. 3:1: Direct = 0.0020, Regression = 0.0020\n\nInterpretation:\n--------------------\nComparison of Direct and Regression Differences:\n  1:1 vs. 2:1: Difference = 0.0000\n  2:1 vs. 3:1: Difference = 0.0000\n  1:1 vs. 3:1: Difference = 0.0000\n\n\nThe direct calculations and the differences in regression coefficients yield very similar results. The response rate (proportion donating) increases as the match ratio increases. However, the magnitude of these increases is quite small. The largest difference is between the 1:1 and 3:1 match rates, with a 0.20 percentage point increase in the likelihood of donation. The increase from 1:1 to 2:1 is 0.19 percentage points, and the increase from 2:1 to 3:1 is only 0.01 percentage points.\nConclusion on Effectiveness:\nWhile there is a trend suggesting that higher match ratios lead to slightly higher donation rates, the small magnitude of these differences, especially the minimal increase from a 2:1 to a 3:1 match, indicates diminishing returns in the effectiveness of increasing the match ratio beyond a certain point. The initial introduction of a match (compared to no match, as seen in the regression intercept) appears to have a more substantial impact than incrementally increasing the generosity of the match.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nimport pandas as pd\nfrom scipy import stats  \n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n# --- Filter data for treatment and control groups ---\ntreatment_amount = data[data['treatment'] == 1]['amount']\ncontrol_amount = data[data['control'] == 1]['amount']\n\n# --- Perform t-test ---\nt_statistic, p_value = stats.ttest_ind(treatment_amount, control_amount)\n\n# --- Print Results ---\nprint(\"T-test Results: Donation Amount by Treatment Status\")\nprint(f\"  T-statistic: {t_statistic:.3f}\")\nprint(f\"  P-value: {p_value:.3f}\")\n\nT-test Results: Donation Amount by Treatment Status\n  T-statistic: 1.861\n  P-value: 0.063\n\n\n\nInterpretation:\nThe t-test comparing average donation amounts between the treatment and control groups yielded a t-statistic of 1.861 and a p-value of 0.063. This p-value is slightly above the conventional significance level of 0.05.\nTherefore, we do not have strong statistical evidence to conclude that the matching grant offer significantly affected the average amount donated. While the t-statistic suggests a trend towards a higher donation amount in the treatment group, the result is not statistically significant at the 0.05 level.\nIn simpler terms, the data doesn’t provide conclusive evidence that the matching grant changed how much people gave, on average. It’s important to remember that ‘not significant’ doesn’t mean ‘no effect’; it simply means we can’t rule out that the observed difference occurred by chance.\nFurther analysis or a larger sample size might be needed to determine if a real, but subtle, effect exists. This result suggests that the matching grant primarily influenced whether people donated (as shown in previous analyses) rather than dramatically altering the size of individual donations.\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation? ####\n\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\ndonors_data = data[data['gave'] == 1]\n\n# --- Regression on Donors Only ---\nformula_donors = 'amount ~ treatment + ratio2 + ratio3'  # amount as dependent\nmodel_donors = sm.ols(formula_donors, data=donors_data).fit()\n\n# --- Print Results Summary ---\nprint(model_donors.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.002\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.6171\nDate:                Fri, 25 Apr 2025   Prob (F-statistic):              0.604\nTime:                        02:12:19   Log-Likelihood:                -5326.1\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1030   BIC:                         1.068e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.424     18.788      0.000      40.784      50.297\ntreatment     -0.3974      3.668     -0.108      0.914      -7.595       6.800\nratio2         0.1944      3.812      0.051      0.959      -7.285       7.674\nratio3        -3.8911      3.808     -1.022      0.307     -11.363       3.581\n==============================================================================\nOmnibus:                      583.474   Durbin-Watson:                   2.036\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5502.639\nSkew:                           2.449   Prob(JB):                         0.00\nKurtosis:                      13.184   Cond. No.                         5.53\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nRegression Analysis of Donation Amounts (Among Donors)\nThis analysis examines the factors influencing the amount donated, focusing only on individuals who made a positive contribution. The OLS regression includes the treatment status (treatment) and the dummy variables for the 2:1 (ratio2) and 3:1 (ratio3) match ratios, with the 1:1 match ratio being the implicit reference category among the match conditions.\nThe intercept of 45.5403 suggests that, for those in the control group who donated, the average donation amount was approximately $45.54. This is statistically significant.\nThe coefficient for the treatment variable is -0.3974 and is not statistically significant (p = 0.914). This indicates that, among those who donated, there is no statistically significant difference in the average donation amount between individuals who received a matching offer (the treatment group) and those who did not (the control group).\nSimilarly, the coefficients for ratio2 (0.1944, p = 0.959) and ratio3 (-3.8911, p = 0.307) are also not statistically significant. This suggests that, among donors, there is no statistically significant difference in the average donation amount between those who received a 2:1 match offer compared to those who received a 1:1 match offer, and no significant difference between those who received a 3:1 match offer compared to those who received a 1:1 match offer.\nCausal Interpretation of the Treatment Coefficient:\nYes, the coefficient for the treatment variable can be interpreted causally for the subpopulation of individuals who decided to donate. Because the initial assignment to treatment and control groups was random, any systematic differences in the average donation amount among those who donated can likely be attributed to the effect of the treatment.\nHowever, it’s crucial to remember that this analysis is conditional on someone having already decided to donate. It doesn’t tell us about the causal effect of the treatment on the decision to donate (which we analyzed earlier). This coefficient specifically addresses the impact of the matching offer on the amount given, given that a donation occurred. The lack of a significant effect here suggests that the matching offer primarily influenced the extensive margin (whether to donate) rather than the intensive margin (how much to donate), at least at a statistically detectable level within this sample of donors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n# --- Filter data for donors only ---\ndonors_data = data[data['gave'] == 1]\n\n# --- Separate data for treatment and control groups among donors ---\ntreatment_donors = donors_data[donors_data['treatment'] == 1]['amount']\ncontrol_donors = donors_data[donors_data['control'] == 1]['amount']\n\n# --- Calculate average donation amounts ---\navg_treatment_donation = treatment_donors.mean()\navg_control_donation = control_donors.mean()\n\n# --- Create the plots ---\nplt.figure(figsize=(12, 6))  # Adjust figure size as needed\n\n# Plot for Treatment Group\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\nplt.hist(treatment_donors, bins=20, alpha=0.7, color='blue')  # Adjust bins as needed\nplt.axvline(avg_treatment_donation, color='red', linestyle='dashed', linewidth=2)  # Add vertical line for average\nplt.title('Donation Amounts - Treatment Group (Donors Only)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.text(avg_treatment_donation + 5, plt.ylim()[1] * 0.9, f\"Avg: {avg_treatment_donation:.2f}\", color='red') #add text\n\n# Plot for Control Group\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\nplt.hist(control_donors, bins=20, alpha=0.7, color='green')  # Adjust bins as needed\nplt.axvline(avg_control_donation, color='red', linestyle='dashed', linewidth=2)  # Add vertical line for average\nplt.title('Donation Amounts - Control Group (Donors Only)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.text(avg_control_donation + 5, plt.ylim()[1] * 0.9, f\"Avg: {avg_control_donation:.2f}\", color='red') #add text\n\nplt.tight_layout()  # Adjust layout to prevent overlap\nplt.show()"
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- Parameters ---\nn_simulations = 10000  # Number of simulated draws\np_control = 0.018     # Probability of donation in the control group\np_treatment = 0.022   # Probability of donation in the treatment group\n\n# --- Simulate Data ---\ncontrol_group = np.random.binomial(1, p_control, n_simulations)  # 1 for donate, 0 for not donate\ntreatment_group = np.random.binomial(1, p_treatment, n_simulations)\n\n# --- Calculate Differences ---\ndifferences = treatment_group - control_group\n\n# --- Calculate Cumulative Average of Differences ---\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_simulations + 1)\n\n# --- Plotting ---\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff)\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label='True Treatment Effect')  # True effect line\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers Simulation')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- Explanation for the reader ---\n\n\n\n\n\n\n\n\nThis chart demonstrates the Law of Large Numbers in the context of our simulated donation experiment. We simulated 10,000 “individuals” in both a control group (donation probability of 0.018) and a treatment group (donation probability of 0.022). For each simulated individual, we determined whether they donated (1) or not (0) using a random draw from a Bernoulli distribution.\nThe blue line in the chart shows the cumulative average difference in donation rates between the treatment and control groups as we include more and more simulated individuals. Initially, with only a few simulations, the average difference is quite variable (“noisy”) because random fluctuations have a large impact.\nHowever, as we simulate more and more individuals, the cumulative average difference converges towards the true treatment effect, which is 0.004 (0.022 - 0.018). This is shown by the red dashed line.\nThe Law of Large Numbers tells us that as the sample size increases, the sample average will approach the true population average. In our simulation, the average difference in donation rates eventually settles down to the true difference in donation probabilities between the treatment and control groups. This illustrates that with a sufficiently large sample, we can accurately estimate the true effect of the treatment.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- Parameters ---\nn_simulations = 1000  # Number of simulations (repetitions)\nsample_sizes = [50, 200, 500, 1000]  # Sample sizes for the histograms\np_control = 0.018  # Probability of donation in the control group\np_treatment = 0.022  # Probability of donation in the treatment group\n\n# --- Function to simulate and calculate average differences ---\ndef simulate_avg_diff(sample_size, p_control, p_treatment, n_simulations):\n    avg_differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, sample_size)\n        treatment_sample = np.random.binomial(1, p_treatment, sample_size)\n        avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n        avg_differences.append(avg_diff)\n    return avg_differences\n\n# --- Create the plots ---\nplt.figure(figsize=(12, 8))\nfor i, sample_size in enumerate(sample_sizes):\n    avg_diffs = simulate_avg_diff(sample_size, p_control, p_treatment, n_simulations)\n    plt.subplot(2, 2, i + 1)\n    plt.hist(avg_diffs, bins=20, alpha=0.7, color='purple')  # Adjust bins as needed\n    plt.title(f'Sample Size = {sample_size}')\n    plt.xlabel('Average Difference')\n    plt.ylabel('Frequency')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis series of four histograms illustrates the Central Limit Theorem. For each histogram, we simulated 1000 experiments. In each experiment, we drew samples from both the control group (donation probability 0.018) and the treatment group (donation probability 0.022) and calculated the difference in the average donation rates between the two groups. We then plotted the distribution of these 1000 average differences.\n\nSample Size = 50: The first histogram shows the distribution of average differences when we draw samples of size 50 from each group. The distribution is somewhat irregular.\nSample Size = 200: As we increase the sample size to 200, the distribution becomes smoother and starts to resemble a bell curve.\nSample Size = 500: With a sample size of 500, the bell curve shape is more pronounced, and the distribution is more concentrated around the true mean difference (0.004).\nSample Size = 1000: Finally, with a sample size of 1000, the distribution is very close to a normal distribution, tightly centered around the true mean difference.\n\nThe Central Limit Theorem states that the distribution of the sample mean (or average) will approach a normal distribution as the sample size increases, regardless of the shape of the original population distribution (in our case, the Bernoulli distribution).\nThese histograms visually demonstrate this theorem. As the sample size grows, the distribution of the average difference becomes more normal, more centered around the true population difference, and less spread out, indicating that our estimates become more precise. This is why statistical tests like the t-test, which rely on the normality assumption, become more reliable with larger sample sizes."
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty hus collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Replace 'your_data.csv' with the actual path to your data file\ndata = pd.read_csv('blueprinty.csv')\n\n# It's always a good idea to get a quick look at the data\nprint(data.head())\nprint(data.info())\nprint(data.describe())\n# The column indicating Blueprinty usage is 'iscustomer' (0 for no, 1 for yes)\ncustomer_users = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\n\n# The column with the number of patents is 'patents'\npatents_column = 'patents'\n\n# Create histograms\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nsns.histplot(customer_users[patents_column], kde=True)\nplt.title('Number of Patents (Blueprinty Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nsns.histplot(non_customers[patents_column], kde=True)\nplt.title('Number of Patents (Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate means\nmean_patents_customer = customer_users[patents_column].mean()\nmean_patents_non_customer = non_customers[patents_column].mean()\n\nprint(f\"\\nMean number of patents (Blueprinty customers): {mean_patents_customer:.2f}\")\nprint(f\"Mean number of patents (Non-customers): {mean_patents_non_customer:.2f}\")\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   patents     1500 non-null   int64  \n 1   region      1500 non-null   object \n 2   age         1500 non-null   float64\n 3   iscustomer  1500 non-null   int64  \ndtypes: float64(1), int64(2), object(1)\nmemory usage: 47.0+ KB\nNone\n           patents          age   iscustomer\ncount  1500.000000  1500.000000  1500.000000\nmean      3.684667    26.357667     0.320667\nstd       2.352500     7.242528     0.466889\nmin       0.000000     9.000000     0.000000\n25%       2.000000    21.000000     0.000000\n50%       3.000000    26.000000     0.000000\n75%       5.000000    31.625000     1.000000\nmax      16.000000    49.000000     1.000000\n\n\n\n\n\n\n\n\n\n\nMean number of patents (Blueprinty customers): 4.13\nMean number of patents (Non-customers): 3.47\n\n\nThe histograms reveal that the distribution of patents awarded is right-skewed for both Blueprinty customers and non-customers, but the distribution for customers appears shifted towards a higher number of patents, with a peak around 4-5 compared to 2-3 for non-customers; this visual difference is supported by the mean number of patents, which is 4.13 for customers and 3.47 for non-customers, suggesting that, on average, Blueprinty customers have a higher number of patents, although further statistical modeling is needed to confirm the significance and account for other factors.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport io\ndata = pd.read_csv('blueprinty.csv')\n\n# Assuming you have already read your data into a pandas DataFrame named 'data'\n# If not, uncomment and replace 'your_data.csv' with the actual path\n# data = pd.read_csv('your_data.csv')\n\n# --- Comparing Regions by Customer Status ---\nregion_customer_table = pd.crosstab(data['region'], data['iscustomer'])\nprint(\"Region vs. Customer Status Contingency Table:\\n\", region_customer_table.to_string())\n\n# Create a stacked bar chart (this will show a plot)\nregion_customer_table.plot(kind='bar', stacked=True, figsize=(8, 6))\nplt.title('Regional Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.xticks(rotation=0)\nplt.legend(title='Is Customer', labels=['No', 'Yes'])\nplt.show()\nplt.close() # Close the plot to avoid it showing up again later\n\n# --- Comparing Ages by Customer Status ---\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.histplot(data[data['iscustomer'] == 1]['age'], kde=True)\nplt.title('Age of Firms (Blueprinty Customers)')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 2)\nsns.histplot(data[data['iscustomer'] == 0]['age'], kde=True)\nplt.title('Age of Firms (Non-Customers)')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='iscustomer', y='age', data=data)\nplt.title('Age of Firms by Customer Status')\nplt.xlabel('Is Customer')\nplt.ylabel('Age (Years)')\nplt.xticks([0, 1], ['No', 'Yes'])\nplt.show()\nplt.close()\n\nage_summary = data.groupby('iscustomer')['age'].describe()\nprint(\"\\nAge Summary Statistics:\\n\", age_summary.to_string())\n\n# --- Comparing Patents (as done previously) ---\ncustomer_users = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\npatents_column = 'patents'\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.histplot(customer_users[patents_column], kde=True)\nplt.title('Number of Patents (Blueprinty Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 2)\nsns.histplot(non_customers[patents_column], kde=True)\nplt.title('Number of Patents (Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nmean_patents_customer = customer_users[patents_column].mean()\nmean_patents_non_customer = non_customers[patents_column].mean()\n\nprint(f\"\\nMean number of patents (Blueprinty customers): {mean_patents_customer:.2f}\")\nprint(f\"Mean number of patents (Non-customers): {mean_patents_non_customer:.2f}\")\n\nRegion vs. Customer Status Contingency Table:\n iscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge Summary Statistics:\n              count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean number of patents (Blueprinty customers): 4.13\nMean number of patents (Non-customers): 3.47\n\n\n\n\nTotal Firms per Region:\nMidwest: 187 (non-customer) + 37 (customer) = 224 Northeast: 273 (non-customer) + 328 (customer) = 601 Northwest: 158 (non-customer) + 29 (customer) = 187 South: 156 (non-customer) + 35 (customer) = 191 Southwest: 245 (non-customer) + 52 (customer) = 297 Distribution of Customers:\nThe Northeast region has the highest number of customers (328), significantly more than any other region. The Southwest region has the second-highest number of customers (52). The Midwest and South regions have a similar, lower number of customers (37 and 35, respectively). The Northwest has the fewest customers (29). Distribution of Non-Customers:\nThe Northeast also has the highest number of non-customers (273). The Southwest has the second-highest number of non-customers (245). The Midwest has a substantial number of non-customers (187). The South and Northwest have a lower number of non-customers (156 and 158, respectively). Proportion of Customers within each Region: To get a better sense of whether customers are disproportionately located in certain regions, we can calculate the percentage of customers in each region:\nMidwest: (37 / 224) * 100% ≈ 16.5% Northeast: (328 / 601) * 100% ≈ 54.6% Northwest: (29 / 187) * 100% ≈ 15.5% South: (35 / 191) * 100% ≈ 18.3% Southwest: (52 / 297) * 100% ≈ 17.5% Observations on Proportions:\nThe proportion of Blueprinty customers is strikingly higher in the Northeast region (around 54.6%) compared to all other regions, where the proportion ranges from approximately 15.5% to 18.3%. Potential Implications for the Marketing Claim:\nThe strong concentration of Blueprinty customers in the Northeast region raises a crucial point. If the Northeast region is inherently more innovative or has a higher propensity for patent applications due to other factors (e.g., industry concentration, research institutions), then the higher number of patents among Blueprinty customers might be partly or even largely attributable to their regional location rather than solely due to the software. To properly assess the effect of Blueprinty, it will be important to control for the “region” variable in any statistical models you build.\n\n\n\nMean Age: The mean age of Blueprinty customers (26.90 years) is slightly higher than the mean age of non-customers (26.10 years). The difference is about 0.8 years. While this difference exists, it doesn’t appear to be dramatically large. Median Age (50%): The median age of customers (26.5 years) is also slightly higher than that of non-customers (25.5 years), with a difference of 1 year. This suggests that the “typical” customer firm might be marginally older. Age Range (Min and Max): The minimum and maximum ages are quite similar for both groups, ranging from around 9-10 years to 47.5-49 years. This indicates that both younger and older firms can be found in both customer and non-customer categories. Interquartile Range (25% and 75%): For non-customers, the interquartile range (IQR) is 31.25 - 21.0 = 10.25 years. For customers, the IQR is 32.50 - 20.5 = 12.0 years. The slightly larger IQR for customers suggests a bit more variability in the middle 50% of their age distribution. Standard Deviation: The standard deviation of age is also slightly higher for customers (7.81 years) compared to non-customers (6.95 years), indicating a slightly wider spread in the ages of customer firms overall. Potential Implications for the Marketing Claim:\nThe fact that Blueprinty customers are, on average, slightly older might be a factor to consider. Older firms might have more established patenting processes or be in industries with a higher propensity to patent. However, the difference in average age is less than a year, so it’s unlikely to be the sole driver of any observed differences in patent numbers. The distributions of age for both groups seem relatively similar, with a central tendency in the mid-twenties.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe likelihood function for a single observation \\(Y\\) from a Poisson distribution with parameter \\(\\lambda\\) is:\n\\[L(\\lambda | Y) = f(Y|\\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\\]\nThe log-likelihood function is:\n\\[\\ell(\\lambda | Y) = \\ln(L(\\lambda | Y)) = -\\lambda + Y \\ln(\\lambda) - \\ln(Y!)\\]\n\nimport numpy as np\nfrom math import factorial\nimport pandas as pd\ndata = pd.read_csv('blueprinty.csv')\n\n\ndef poisson_loglikelihood(lambd, Y):\n  if lambd &lt;= 0 or not Y == int(Y) or Y &lt; 0:\n    return -np.inf\n  return -lambd + Y * np.log(lambd) - np.log(factorial(Y))\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom math import factorial\n\n# Use the mean number of patents from the entire dataset as Y\nmean_patents_overall = data['patents'].mean()\nY_plot = int(round(mean_patents_overall))\n\n# Define a range of lambda values\nlambda_values = np.linspace(0.1, 2 * mean_patents_overall, 200)\n\n# Calculate log-likelihood values\nloglikelihoods = [poisson_loglikelihood(lambd, Y_plot) for lambd in lambda_values]\n\n# Plot lambda vs. log-likelihood\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, loglikelihoods)\nplt.title(f'Log-Likelihood vs. Lambda (Y = {Y_plot})')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood ℓ(λ|Y)')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe plot shows the log-likelihood of observing Y=4 (the rounded mean number of patents in our dataset) for different values of the Poisson parameter λ. The curve exhibits a clear peak. This peak represents the value of λ that maximizes the log-likelihood (and thus the likelihood) of observing our data. In this case, the log-likelihood appears to be maximized when λ is approximately 4. This visual confirms that the Maximum Likelihood Estimate (MLE) for λ, given a single observation equal to the sample mean, is the sample mean itself.\nIf we take the log-likelihood function for a sample of \\(n\\) i.i.d. Poisson observations \\(y_1, y_2, ..., y_n\\):\n\\[\\ell(\\lambda | y_1, ..., y_n) = -n\\lambda + \\left(\\sum_{i=1}^{n} y_i\\right) \\ln(\\lambda) - \\sum_{i=1}^{n} \\ln(y_i!)\\]\nTo find the MLE for \\(\\lambda\\), we take the first derivative of the log-likelihood with respect to \\(\\lambda\\) and set it to zero:\n\\[\\frac{\\partial \\ell(\\lambda)}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^{n} y_i}{\\lambda} = 0\\]\nSolving for \\(\\lambda\\):\n\\[\\frac{\\sum_{i=1}^{n} y_i}{\\lambda} = n\\]\n\\[\\lambda = \\frac{\\sum_{i=1}^{n} y_i}{n} = \\bar{Y}\\]\nThus, the Maximum Likelihood Estimate (\\(\\lambda_{MLE}\\)) for the Poisson parameter \\(\\lambda\\) is indeed the sample mean (\\(\\bar{Y}\\)). This result aligns with the property that the mean of a Poisson distribution is equal to its parameter \\(\\lambda\\).\nTo find the Maximum Likelihood Estimate (MLE) for the Poisson parameter λ using numerical optimization, we can use the minimize function from the scipy.optimize library in Python. We define the negative of the log-likelihood function (since minimize performs minimization) for our observed number of patents. By providing an initial guess for λ (such as the sample mean) and running the optimization, we can find the value of λ that minimizes the negative log-likelihood, which is equivalent to maximizing the log-likelihood.\n\nimport pandas as pd\nimport numpy as np\nfrom math import factorial\nfrom scipy.optimize import minimize\n\ndata = pd.read_csv('blueprinty.csv')\nY_observed = data['patents'].values  # Get all observed number of patents\n\ndef negative_poisson_loglikelihood(lambd, Y):\n  \"\"\"Calculates the negative log-likelihood for the entire sample.\"\"\"\n  if lambd &lt;= 0:\n    return np.inf\n  log_likelihood = np.sum(-lambd + Y * np.log(lambd) - np.log(np.array([factorial(y) for y in Y])))\n  return -log_likelihood\n\n# Initial guess for lambda (e.g., the sample mean)\ninitial_lambda = np.mean(Y_observed)\n\n# Perform the optimization\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y_observed,), method='L-BFGS-B', bounds=[(0.001, None)])\n\n# Extract the MLE estimate for lambda\nmle_lambda = result.x[0]\n\nprint(f\"Maximum Likelihood Estimate (MLE) for lambda: {mle_lambda:.4f}\")\nprint(f\"Sample Mean of Patents: {initial_lambda:.4f}\")\n\nMaximum Likelihood Estimate (MLE) for lambda: 3.6847\nSample Mean of Patents: 3.6847\n\n\nUsing numerical optimization with the minimize function from scipy.optimize in Python, we found the Maximum Likelihood Estimate (MLE) for the Poisson parameter λ to be approximately 3.6847. This value is remarkably close to the sample mean of the number of patents in our dataset, which is also 3.6847. This empirical result reinforces the theoretical finding that the MLE of λ for a Poisson distribution is the sample mean.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport pandas as pd\nimport numpy as np\nfrom math import factorial\nfrom scipy.optimize import minimize\nimport statsmodels.api as sm\n\ndata = pd.read_csv('blueprinty.csv')\nY_observed = data['patents'].values\n\n# Prepare the covariate matrix X, ensuring numeric types\ndata['age_squared'] = pd.to_numeric(data['age'], errors='coerce')**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\nX['age'] = pd.to_numeric(X['age'], errors='coerce')\nX['age_squared'] = pd.to_numeric(X['age_squared'], errors='coerce')\nX['iscustomer'] = pd.to_numeric(X['iscustomer'], errors='coerce')\nX = X[['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']].values\n# Add a constant term (intercept) to the matrix X\nX = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1).astype(float)\n\ndef negative_poisson_regression_loglikelihood(beta, Y, X):\n  \"\"\"Calculates the negative log-likelihood for Poisson regression.\"\"\"\n  if np.any(np.isnan(beta)):\n    return np.inf\n  log_lambda = np.dot(X, beta)\n  lambda_i = np.exp(log_lambda)\n  log_likelihood = np.sum(-lambda_i + Y * log_lambda - np.log(np.array([factorial(y) for y in Y])))\n  return -log_likelihood\n\n# Initial guess for beta (zeros), ensuring float type\ninitial_beta = np.zeros(X.shape[1], dtype=float)\n\n# Perform the optimization to find MLE\nresult = minimize(negative_poisson_regression_loglikelihood, initial_beta, args=(Y_observed, X), method='BFGS', jac=None, hess=None)\n\n# Extract the MLE estimates for beta\nmle_beta = result.x\n\n# --- Using statsmodels for standard errors ---\npoisson_model = sm.GLM(Y_observed, X, family=sm.families.Poisson()).fit()\nstandard_errors = poisson_model.bse\ncoefficients = poisson_model.params\n\n# Create a table of coefficients and standard errors\nresults_table = pd.DataFrame({\n    'Coefficient': coefficients,\n    'Standard Error': standard_errors\n})\n\nprint(\"\\nTable of Coefficients and Standard Errors (using statsmodels):\\n\", results_table)\n\n\nTable of Coefficients and Standard Errors (using statsmodels):\n    Coefficient  Standard Error\n0    -0.508920        0.183179\n1     0.148619        0.013869\n2    -0.002970        0.000258\n3     0.207591        0.030895\n4     0.029170        0.043625\n5    -0.017575        0.053781\n6     0.056561        0.052662\n7     0.050576        0.047198\n\n\n/tmp/ipykernel_29660/2732339304.py:25: RuntimeWarning:\n\noverflow encountered in exp\n\n/opt/conda/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning:\n\noverflow encountered in reduce\n\n/opt/conda/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/tmp/ipykernel_29660/2732339304.py:25: RuntimeWarning:\n\noverflow encountered in exp\n\n\n\n\n\nWe estimated a Poisson regression model to understand the relationship between the number of patents awarded and firm characteristics, including age, age squared, region, and whether the firm is a Blueprinty customer (iscustomer).\n\n\n\nIntercept: The intercept is estimated at -0.509. Age: The positive coefficient for age (0.149) suggests that, holding other factors constant, older firms tend to have a higher expected number of patents. Age Squared: The negative coefficient for age squared (-0.003) indicates a potential non-linear relationship with age, suggesting that the positive effect of age on patents might diminish at higher ages. Blueprinty Customer (iscustomer): The positive and statistically significant coefficient for iscustomer (0.208) is of primary interest. To interpret this, we exponentiate the coefficient: exp(0.208)≈1.23. This suggests that, holding other factors constant, Blueprinty customers have an estimated expected number of patents that is about 23% higher than non-customers. Region: The coefficients for the region dummy variables (Northeast, Northwest, South, Southwest) are relative to the baseline region (Midwest). For example, firms in the Northeast have an estimated expected number of patents that is exp(0.029)≈1.03 times that of firms in the Midwest, after controlling for other variables. The significance of these regional effects would need to be assessed based on their standard errors. These results provide evidence that, even after controlling for age and region, Blueprinty customers tend to have a higher expected number of patents compared to non-customers in this dataset.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.genmod import families\n\ndata = pd.read_csv('blueprinty.csv')\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age']**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\n\n# Select the columns for our model\nX_cols = ['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']\nX = X[X_cols].copy() # Use .copy() to avoid SettingWithCopyWarning\n\n# Explicitly convert X columns to float64\nfor col in X.columns:\n    X[col] = pd.to_numeric(X[col], errors='coerce')\n\n# Add a constant term (intercept) to the matrix X\nX = sm.add_constant(X, prepend=True)\n\n# Ensure the constant is also float\nX['const'] = pd.to_numeric(X['const'], errors='coerce')\n\nY_observed = data['patents']\n\n# Try converting X to numpy array with float dtype\nX_array = np.asarray(X, dtype=float)\n\n# Fit the Poisson GLM\ntry:\n    poisson_glm_model = sm.GLM(Y_observed, X_array, family=families.Poisson()).fit()\n    # Print the summary of the model\n    print(poisson_glm_model.summary())\nexcept ValueError as e:\n    print(f\"ValueError during model fitting: {e}\")\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        21:20:39   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nx1             0.1486      0.014     10.716      0.000       0.121       0.176\nx2            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx3             0.2076      0.031      6.719      0.000       0.147       0.268\nx4             0.0292      0.044      0.669      0.504      -0.056       0.115\nx5            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx6             0.0566      0.053      1.074      0.283      -0.047       0.160\nx7             0.0506      0.047      1.072      0.284      -0.042       0.143\n==============================================================================\n\n\n\n\n\nThe results of the Poisson regression model indicate that firm age, age squared, and being a Blueprinty customer are statistically significant predictors of the number of patents awarded. The positive coefficient for iscustomer suggests that, even after controlling for age and regional location, Blueprinty customers have a significantly higher expected number of patents (approximately 23% higher) compared to non-customers. The effects of the different regions compared to the Midwest baseline were not found to be statistically significant in this model.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.genmod import families\n\ndata = pd.read_csv('blueprinty.csv')\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age']**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\nX = X[['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']].copy()\n\n# Explicitly convert X columns to float64\nfor col in X.columns:\n    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)\n\n# Add a constant term (intercept) to the matrix X\nX = sm.add_constant(X, prepend=True)\nX['const'] = pd.to_numeric(X['const'], errors='coerce').astype(float)\n\nY_observed = data['patents']\n\n# Fit the Poisson GLM\npoisson_glm_model = sm.GLM(Y_observed, X, family=families.Poisson()).fit()\n\n# Print model summary (for inspection)\nprint(\"\\nPoisson GLM Model Summary before predict:\\n\", poisson_glm_model.summary())\n\n# Print columns of X\nprint(\"\\nColumns of X before creating X_0 and X_1:\\n\", X.columns)\n\n# Create X_0: X data with iscustomer = 0 for all observations\nX_0 = X.copy()\nX_0['iscustomer'] = float(0)\nprint(\"\\nX_0 data types before predict:\\n\", X_0.dtypes)\nprint(\"\\nX_0 head before predict:\\n\", X_0.head())\nprint(\"\\nNumPy array dtype of X_0:\\n\", np.asarray(X_0).dtype)\n\n# Create X_1: X data with iscustomer = 1 for all observations\nX_1 = X.copy()\nX_1['iscustomer'] = float(1)\nprint(\"\\nX_1 data types before predict:\\n\", X_1.dtypes)\nprint(\"\\nX_1 head before predict:\\n\", X_1.head())\nprint(\"\\nNumPy array dtype of X_1:\\n\", np.asarray(X_1).dtype)\n\n# Try predicting on the original X\ntry:\n    log_y_pred_original = poisson_glm_model.predict(X)\n    print(\"\\nPrediction on original X successful.\")\nexcept ValueError as e:\n    print(f\"\\nValueError during prediction on original X: {e}\")\n\n# Predict the log of the expected number of patents for X_0 and X_1\ntry:\n    log_y_pred_0 = poisson_glm_model.predict(X_0)\n    log_y_pred_1 = poisson_glm_model.predict(X_1)\n\n    # The predicted number of patents is exp(log_y_pred)\n    y_pred_0 = np.exp(log_y_pred_0)\n    y_pred_1 = np.exp(log_y_pred_1)\n\n    # Calculate the difference in predicted number of patents\n    difference = y_pred_1 - y_pred_0\n\n    # Calculate the average difference\n    average_difference = np.mean(difference)\n\n    print(f\"\\nAverage predicted number of patents (if all were customers): {np.mean(y_pred_1):.2f}\")\n    print(f\"Average predicted number of patents (if all were non-customers): {np.mean(y_pred_0):.2f}\")\n    print(f\"Average difference in predicted number of patents due to Blueprinty: {average_difference:.2f}\")\n\nexcept ValueError as e:\n    print(f\"ValueError during prediction: {e}\")\n\n\nPoisson GLM Model Summary before predict:\n                  Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        21:20:39   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst               -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage                  0.1486      0.014     10.716      0.000       0.121       0.176\nage_squared         -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\nColumns of X before creating X_0 and X_1:\n Index(['const', 'age', 'age_squared', 'iscustomer', 'region_Northeast',\n       'region_Northwest', 'region_South', 'region_Southwest'],\n      dtype='object')\n\nX_0 data types before predict:\n const               float64\nage                 float64\nage_squared         float64\niscustomer          float64\nregion_Northeast    float64\nregion_Northwest    float64\nregion_South        float64\nregion_Southwest    float64\ndtype: object\n\nX_0 head before predict:\n    const   age  age_squared  iscustomer  region_Northeast  region_Northwest  \\\n0    1.0  32.5      1056.25         0.0               0.0               0.0   \n1    1.0  37.5      1406.25         0.0               0.0               0.0   \n2    1.0  27.0       729.00         0.0               0.0               1.0   \n3    1.0  24.5       600.25         0.0               1.0               0.0   \n4    1.0  37.0      1369.00         0.0               0.0               0.0   \n\n   region_South  region_Southwest  \n0           0.0               0.0  \n1           0.0               1.0  \n2           0.0               0.0  \n3           0.0               0.0  \n4           0.0               1.0  \n\nNumPy array dtype of X_0:\n float64\n\nX_1 data types before predict:\n const               float64\nage                 float64\nage_squared         float64\niscustomer          float64\nregion_Northeast    float64\nregion_Northwest    float64\nregion_South        float64\nregion_Southwest    float64\ndtype: object\n\nX_1 head before predict:\n    const   age  age_squared  iscustomer  region_Northeast  region_Northwest  \\\n0    1.0  32.5      1056.25         1.0               0.0               0.0   \n1    1.0  37.5      1406.25         1.0               0.0               0.0   \n2    1.0  27.0       729.00         1.0               0.0               1.0   \n3    1.0  24.5       600.25         1.0               1.0               0.0   \n4    1.0  37.0      1369.00         1.0               0.0               0.0   \n\n   region_South  region_Southwest  \n0           0.0               0.0  \n1           0.0               1.0  \n2           0.0               0.0  \n3           0.0               0.0  \n4           0.0               1.0  \n\nNumPy array dtype of X_1:\n float64\n\nPrediction on original X successful.\n\nAverage predicted number of patents (if all were customers): 83.10\nAverage predicted number of patents (if all were non-customers): 35.49\nAverage difference in predicted number of patents due to Blueprinty: 47.61\n\n\n\n\n\nBased on our analysis, the average predicted number of patents over five years for firms in our dataset, if they were all Blueprinty customers, is approximately 83.10. In contrast, the average predicted number of patents if none of them were customers is about 35.49. The average difference between these two scenarios is 47.61 patents. This suggests a substantial positive effect of using Blueprinty’s software on patent success, as our model predicts that, on average, firms using the software are expected to be awarded approximately 47.61 more patents over five years compared to non-users, while holding age and regional location constant at their observed levels."
  },
  {
    "objectID": "projects/project2/index.html#blueprinty-case-study",
    "href": "projects/project2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty hus collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Replace 'your_data.csv' with the actual path to your data file\ndata = pd.read_csv('blueprinty.csv')\n\n# It's always a good idea to get a quick look at the data\nprint(data.head())\nprint(data.info())\nprint(data.describe())\n# The column indicating Blueprinty usage is 'iscustomer' (0 for no, 1 for yes)\ncustomer_users = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\n\n# The column with the number of patents is 'patents'\npatents_column = 'patents'\n\n# Create histograms\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nsns.histplot(customer_users[patents_column], kde=True)\nplt.title('Number of Patents (Blueprinty Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nsns.histplot(non_customers[patents_column], kde=True)\nplt.title('Number of Patents (Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate means\nmean_patents_customer = customer_users[patents_column].mean()\nmean_patents_non_customer = non_customers[patents_column].mean()\n\nprint(f\"\\nMean number of patents (Blueprinty customers): {mean_patents_customer:.2f}\")\nprint(f\"Mean number of patents (Non-customers): {mean_patents_non_customer:.2f}\")\n\n   patents     region   age  iscustomer\n0        0    Midwest  32.5           0\n1        3  Southwest  37.5           0\n2        4  Northwest  27.0           1\n3        3  Northeast  24.5           0\n4        3  Southwest  37.0           0\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   patents     1500 non-null   int64  \n 1   region      1500 non-null   object \n 2   age         1500 non-null   float64\n 3   iscustomer  1500 non-null   int64  \ndtypes: float64(1), int64(2), object(1)\nmemory usage: 47.0+ KB\nNone\n           patents          age   iscustomer\ncount  1500.000000  1500.000000  1500.000000\nmean      3.684667    26.357667     0.320667\nstd       2.352500     7.242528     0.466889\nmin       0.000000     9.000000     0.000000\n25%       2.000000    21.000000     0.000000\n50%       3.000000    26.000000     0.000000\n75%       5.000000    31.625000     1.000000\nmax      16.000000    49.000000     1.000000\n\n\n\n\n\n\n\n\n\n\nMean number of patents (Blueprinty customers): 4.13\nMean number of patents (Non-customers): 3.47\n\n\nThe histograms reveal that the distribution of patents awarded is right-skewed for both Blueprinty customers and non-customers, but the distribution for customers appears shifted towards a higher number of patents, with a peak around 4-5 compared to 2-3 for non-customers; this visual difference is supported by the mean number of patents, which is 4.13 for customers and 3.47 for non-customers, suggesting that, on average, Blueprinty customers have a higher number of patents, although further statistical modeling is needed to confirm the significance and account for other factors.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport io\ndata = pd.read_csv('blueprinty.csv')\n\n# Assuming you have already read your data into a pandas DataFrame named 'data'\n# If not, uncomment and replace 'your_data.csv' with the actual path\n# data = pd.read_csv('your_data.csv')\n\n# --- Comparing Regions by Customer Status ---\nregion_customer_table = pd.crosstab(data['region'], data['iscustomer'])\nprint(\"Region vs. Customer Status Contingency Table:\\n\", region_customer_table.to_string())\n\n# Create a stacked bar chart (this will show a plot)\nregion_customer_table.plot(kind='bar', stacked=True, figsize=(8, 6))\nplt.title('Regional Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Number of Firms')\nplt.xticks(rotation=0)\nplt.legend(title='Is Customer', labels=['No', 'Yes'])\nplt.show()\nplt.close() # Close the plot to avoid it showing up again later\n\n# --- Comparing Ages by Customer Status ---\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.histplot(data[data['iscustomer'] == 1]['age'], kde=True)\nplt.title('Age of Firms (Blueprinty Customers)')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 2)\nsns.histplot(data[data['iscustomer'] == 0]['age'], kde=True)\nplt.title('Age of Firms (Non-Customers)')\nplt.xlabel('Age (Years)')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='iscustomer', y='age', data=data)\nplt.title('Age of Firms by Customer Status')\nplt.xlabel('Is Customer')\nplt.ylabel('Age (Years)')\nplt.xticks([0, 1], ['No', 'Yes'])\nplt.show()\nplt.close()\n\nage_summary = data.groupby('iscustomer')['age'].describe()\nprint(\"\\nAge Summary Statistics:\\n\", age_summary.to_string())\n\n# --- Comparing Patents (as done previously) ---\ncustomer_users = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\npatents_column = 'patents'\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.histplot(customer_users[patents_column], kde=True)\nplt.title('Number of Patents (Blueprinty Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 2)\nsns.histplot(non_customers[patents_column], kde=True)\nplt.title('Number of Patents (Non-Customers)')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.show()\nplt.close()\n\nmean_patents_customer = customer_users[patents_column].mean()\nmean_patents_non_customer = non_customers[patents_column].mean()\n\nprint(f\"\\nMean number of patents (Blueprinty customers): {mean_patents_customer:.2f}\")\nprint(f\"Mean number of patents (Non-customers): {mean_patents_non_customer:.2f}\")\n\nRegion vs. Customer Status Contingency Table:\n iscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge Summary Statistics:\n              count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean number of patents (Blueprinty customers): 4.13\nMean number of patents (Non-customers): 3.47\n\n\n\n\nTotal Firms per Region:\nMidwest: 187 (non-customer) + 37 (customer) = 224 Northeast: 273 (non-customer) + 328 (customer) = 601 Northwest: 158 (non-customer) + 29 (customer) = 187 South: 156 (non-customer) + 35 (customer) = 191 Southwest: 245 (non-customer) + 52 (customer) = 297 Distribution of Customers:\nThe Northeast region has the highest number of customers (328), significantly more than any other region. The Southwest region has the second-highest number of customers (52). The Midwest and South regions have a similar, lower number of customers (37 and 35, respectively). The Northwest has the fewest customers (29). Distribution of Non-Customers:\nThe Northeast also has the highest number of non-customers (273). The Southwest has the second-highest number of non-customers (245). The Midwest has a substantial number of non-customers (187). The South and Northwest have a lower number of non-customers (156 and 158, respectively). Proportion of Customers within each Region: To get a better sense of whether customers are disproportionately located in certain regions, we can calculate the percentage of customers in each region:\nMidwest: (37 / 224) * 100% ≈ 16.5% Northeast: (328 / 601) * 100% ≈ 54.6% Northwest: (29 / 187) * 100% ≈ 15.5% South: (35 / 191) * 100% ≈ 18.3% Southwest: (52 / 297) * 100% ≈ 17.5% Observations on Proportions:\nThe proportion of Blueprinty customers is strikingly higher in the Northeast region (around 54.6%) compared to all other regions, where the proportion ranges from approximately 15.5% to 18.3%. Potential Implications for the Marketing Claim:\nThe strong concentration of Blueprinty customers in the Northeast region raises a crucial point. If the Northeast region is inherently more innovative or has a higher propensity for patent applications due to other factors (e.g., industry concentration, research institutions), then the higher number of patents among Blueprinty customers might be partly or even largely attributable to their regional location rather than solely due to the software. To properly assess the effect of Blueprinty, it will be important to control for the “region” variable in any statistical models you build.\n\n\n\nMean Age: The mean age of Blueprinty customers (26.90 years) is slightly higher than the mean age of non-customers (26.10 years). The difference is about 0.8 years. While this difference exists, it doesn’t appear to be dramatically large. Median Age (50%): The median age of customers (26.5 years) is also slightly higher than that of non-customers (25.5 years), with a difference of 1 year. This suggests that the “typical” customer firm might be marginally older. Age Range (Min and Max): The minimum and maximum ages are quite similar for both groups, ranging from around 9-10 years to 47.5-49 years. This indicates that both younger and older firms can be found in both customer and non-customer categories. Interquartile Range (25% and 75%): For non-customers, the interquartile range (IQR) is 31.25 - 21.0 = 10.25 years. For customers, the IQR is 32.50 - 20.5 = 12.0 years. The slightly larger IQR for customers suggests a bit more variability in the middle 50% of their age distribution. Standard Deviation: The standard deviation of age is also slightly higher for customers (7.81 years) compared to non-customers (6.95 years), indicating a slightly wider spread in the ages of customer firms overall. Potential Implications for the Marketing Claim:\nThe fact that Blueprinty customers are, on average, slightly older might be a factor to consider. Older firms might have more established patenting processes or be in industries with a higher propensity to patent. However, the difference in average age is less than a year, so it’s unlikely to be the sole driver of any observed differences in patent numbers. The distributions of age for both groups seem relatively similar, with a central tendency in the mid-twenties.\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe likelihood function for a single observation \\(Y\\) from a Poisson distribution with parameter \\(\\lambda\\) is:\n\\[L(\\lambda | Y) = f(Y|\\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\\]\nThe log-likelihood function is:\n\\[\\ell(\\lambda | Y) = \\ln(L(\\lambda | Y)) = -\\lambda + Y \\ln(\\lambda) - \\ln(Y!)\\]\n\nimport numpy as np\nfrom math import factorial\nimport pandas as pd\ndata = pd.read_csv('blueprinty.csv')\n\n\ndef poisson_loglikelihood(lambd, Y):\n  if lambd &lt;= 0 or not Y == int(Y) or Y &lt; 0:\n    return -np.inf\n  return -lambd + Y * np.log(lambd) - np.log(factorial(Y))\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom math import factorial\n\n# Use the mean number of patents from the entire dataset as Y\nmean_patents_overall = data['patents'].mean()\nY_plot = int(round(mean_patents_overall))\n\n# Define a range of lambda values\nlambda_values = np.linspace(0.1, 2 * mean_patents_overall, 200)\n\n# Calculate log-likelihood values\nloglikelihoods = [poisson_loglikelihood(lambd, Y_plot) for lambd in lambda_values]\n\n# Plot lambda vs. log-likelihood\nplt.figure(figsize=(10, 6))\nplt.plot(lambda_values, loglikelihoods)\nplt.title(f'Log-Likelihood vs. Lambda (Y = {Y_plot})')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood ℓ(λ|Y)')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe plot shows the log-likelihood of observing Y=4 (the rounded mean number of patents in our dataset) for different values of the Poisson parameter λ. The curve exhibits a clear peak. This peak represents the value of λ that maximizes the log-likelihood (and thus the likelihood) of observing our data. In this case, the log-likelihood appears to be maximized when λ is approximately 4. This visual confirms that the Maximum Likelihood Estimate (MLE) for λ, given a single observation equal to the sample mean, is the sample mean itself.\nIf we take the log-likelihood function for a sample of \\(n\\) i.i.d. Poisson observations \\(y_1, y_2, ..., y_n\\):\n\\[\\ell(\\lambda | y_1, ..., y_n) = -n\\lambda + \\left(\\sum_{i=1}^{n} y_i\\right) \\ln(\\lambda) - \\sum_{i=1}^{n} \\ln(y_i!)\\]\nTo find the MLE for \\(\\lambda\\), we take the first derivative of the log-likelihood with respect to \\(\\lambda\\) and set it to zero:\n\\[\\frac{\\partial \\ell(\\lambda)}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^{n} y_i}{\\lambda} = 0\\]\nSolving for \\(\\lambda\\):\n\\[\\frac{\\sum_{i=1}^{n} y_i}{\\lambda} = n\\]\n\\[\\lambda = \\frac{\\sum_{i=1}^{n} y_i}{n} = \\bar{Y}\\]\nThus, the Maximum Likelihood Estimate (\\(\\lambda_{MLE}\\)) for the Poisson parameter \\(\\lambda\\) is indeed the sample mean (\\(\\bar{Y}\\)). This result aligns with the property that the mean of a Poisson distribution is equal to its parameter \\(\\lambda\\).\nTo find the Maximum Likelihood Estimate (MLE) for the Poisson parameter λ using numerical optimization, we can use the minimize function from the scipy.optimize library in Python. We define the negative of the log-likelihood function (since minimize performs minimization) for our observed number of patents. By providing an initial guess for λ (such as the sample mean) and running the optimization, we can find the value of λ that minimizes the negative log-likelihood, which is equivalent to maximizing the log-likelihood.\n\nimport pandas as pd\nimport numpy as np\nfrom math import factorial\nfrom scipy.optimize import minimize\n\ndata = pd.read_csv('blueprinty.csv')\nY_observed = data['patents'].values  # Get all observed number of patents\n\ndef negative_poisson_loglikelihood(lambd, Y):\n  \"\"\"Calculates the negative log-likelihood for the entire sample.\"\"\"\n  if lambd &lt;= 0:\n    return np.inf\n  log_likelihood = np.sum(-lambd + Y * np.log(lambd) - np.log(np.array([factorial(y) for y in Y])))\n  return -log_likelihood\n\n# Initial guess for lambda (e.g., the sample mean)\ninitial_lambda = np.mean(Y_observed)\n\n# Perform the optimization\nresult = minimize(negative_poisson_loglikelihood, initial_lambda, args=(Y_observed,), method='L-BFGS-B', bounds=[(0.001, None)])\n\n# Extract the MLE estimate for lambda\nmle_lambda = result.x[0]\n\nprint(f\"Maximum Likelihood Estimate (MLE) for lambda: {mle_lambda:.4f}\")\nprint(f\"Sample Mean of Patents: {initial_lambda:.4f}\")\n\nMaximum Likelihood Estimate (MLE) for lambda: 3.6847\nSample Mean of Patents: 3.6847\n\n\nUsing numerical optimization with the minimize function from scipy.optimize in Python, we found the Maximum Likelihood Estimate (MLE) for the Poisson parameter λ to be approximately 3.6847. This value is remarkably close to the sample mean of the number of patents in our dataset, which is also 3.6847. This empirical result reinforces the theoretical finding that the MLE of λ for a Poisson distribution is the sample mean.\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\nimport pandas as pd\nimport numpy as np\nfrom math import factorial\nfrom scipy.optimize import minimize\nimport statsmodels.api as sm\n\ndata = pd.read_csv('blueprinty.csv')\nY_observed = data['patents'].values\n\n# Prepare the covariate matrix X, ensuring numeric types\ndata['age_squared'] = pd.to_numeric(data['age'], errors='coerce')**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\nX['age'] = pd.to_numeric(X['age'], errors='coerce')\nX['age_squared'] = pd.to_numeric(X['age_squared'], errors='coerce')\nX['iscustomer'] = pd.to_numeric(X['iscustomer'], errors='coerce')\nX = X[['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']].values\n# Add a constant term (intercept) to the matrix X\nX = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1).astype(float)\n\ndef negative_poisson_regression_loglikelihood(beta, Y, X):\n  \"\"\"Calculates the negative log-likelihood for Poisson regression.\"\"\"\n  if np.any(np.isnan(beta)):\n    return np.inf\n  log_lambda = np.dot(X, beta)\n  lambda_i = np.exp(log_lambda)\n  log_likelihood = np.sum(-lambda_i + Y * log_lambda - np.log(np.array([factorial(y) for y in Y])))\n  return -log_likelihood\n\n# Initial guess for beta (zeros), ensuring float type\ninitial_beta = np.zeros(X.shape[1], dtype=float)\n\n# Perform the optimization to find MLE\nresult = minimize(negative_poisson_regression_loglikelihood, initial_beta, args=(Y_observed, X), method='BFGS', jac=None, hess=None)\n\n# Extract the MLE estimates for beta\nmle_beta = result.x\n\n# --- Using statsmodels for standard errors ---\npoisson_model = sm.GLM(Y_observed, X, family=sm.families.Poisson()).fit()\nstandard_errors = poisson_model.bse\ncoefficients = poisson_model.params\n\n# Create a table of coefficients and standard errors\nresults_table = pd.DataFrame({\n    'Coefficient': coefficients,\n    'Standard Error': standard_errors\n})\n\nprint(\"\\nTable of Coefficients and Standard Errors (using statsmodels):\\n\", results_table)\n\n\nTable of Coefficients and Standard Errors (using statsmodels):\n    Coefficient  Standard Error\n0    -0.508920        0.183179\n1     0.148619        0.013869\n2    -0.002970        0.000258\n3     0.207591        0.030895\n4     0.029170        0.043625\n5    -0.017575        0.053781\n6     0.056561        0.052662\n7     0.050576        0.047198\n\n\n/tmp/ipykernel_29660/2732339304.py:25: RuntimeWarning:\n\noverflow encountered in exp\n\n/opt/conda/lib/python3.12/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning:\n\noverflow encountered in reduce\n\n/opt/conda/lib/python3.12/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning:\n\ninvalid value encountered in subtract\n\n/tmp/ipykernel_29660/2732339304.py:25: RuntimeWarning:\n\noverflow encountered in exp\n\n\n\n\n\nWe estimated a Poisson regression model to understand the relationship between the number of patents awarded and firm characteristics, including age, age squared, region, and whether the firm is a Blueprinty customer (iscustomer).\n\n\n\nIntercept: The intercept is estimated at -0.509. Age: The positive coefficient for age (0.149) suggests that, holding other factors constant, older firms tend to have a higher expected number of patents. Age Squared: The negative coefficient for age squared (-0.003) indicates a potential non-linear relationship with age, suggesting that the positive effect of age on patents might diminish at higher ages. Blueprinty Customer (iscustomer): The positive and statistically significant coefficient for iscustomer (0.208) is of primary interest. To interpret this, we exponentiate the coefficient: exp(0.208)≈1.23. This suggests that, holding other factors constant, Blueprinty customers have an estimated expected number of patents that is about 23% higher than non-customers. Region: The coefficients for the region dummy variables (Northeast, Northwest, South, Southwest) are relative to the baseline region (Midwest). For example, firms in the Northeast have an estimated expected number of patents that is exp(0.029)≈1.03 times that of firms in the Midwest, after controlling for other variables. The significance of these regional effects would need to be assessed based on their standard errors. These results provide evidence that, even after controlling for age and region, Blueprinty customers tend to have a higher expected number of patents compared to non-customers in this dataset.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.genmod import families\n\ndata = pd.read_csv('blueprinty.csv')\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age']**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\n\n# Select the columns for our model\nX_cols = ['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']\nX = X[X_cols].copy() # Use .copy() to avoid SettingWithCopyWarning\n\n# Explicitly convert X columns to float64\nfor col in X.columns:\n    X[col] = pd.to_numeric(X[col], errors='coerce')\n\n# Add a constant term (intercept) to the matrix X\nX = sm.add_constant(X, prepend=True)\n\n# Ensure the constant is also float\nX['const'] = pd.to_numeric(X['const'], errors='coerce')\n\nY_observed = data['patents']\n\n# Try converting X to numpy array with float dtype\nX_array = np.asarray(X, dtype=float)\n\n# Fit the Poisson GLM\ntry:\n    poisson_glm_model = sm.GLM(Y_observed, X_array, family=families.Poisson()).fit()\n    # Print the summary of the model\n    print(poisson_glm_model.summary())\nexcept ValueError as e:\n    print(f\"ValueError during model fitting: {e}\")\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        21:20:39   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nx1             0.1486      0.014     10.716      0.000       0.121       0.176\nx2            -0.0030      0.000    -11.513      0.000      -0.003      -0.002\nx3             0.2076      0.031      6.719      0.000       0.147       0.268\nx4             0.0292      0.044      0.669      0.504      -0.056       0.115\nx5            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx6             0.0566      0.053      1.074      0.283      -0.047       0.160\nx7             0.0506      0.047      1.072      0.284      -0.042       0.143\n==============================================================================\n\n\n\n\n\nThe results of the Poisson regression model indicate that firm age, age squared, and being a Blueprinty customer are statistically significant predictors of the number of patents awarded. The positive coefficient for iscustomer suggests that, even after controlling for age and regional location, Blueprinty customers have a significantly higher expected number of patents (approximately 23% higher) compared to non-customers. The effects of the different regions compared to the Midwest baseline were not found to be statistically significant in this model.\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.genmod import families\n\ndata = pd.read_csv('blueprinty.csv')\n\n# Prepare the covariate matrix X\ndata['age_squared'] = data['age']**2\nX = pd.get_dummies(data, columns=['region'], drop_first=True)\nX = X[['age', 'age_squared', 'iscustomer', 'region_Northeast', 'region_Northwest', 'region_South', 'region_Southwest']].copy()\n\n# Explicitly convert X columns to float64\nfor col in X.columns:\n    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)\n\n# Add a constant term (intercept) to the matrix X\nX = sm.add_constant(X, prepend=True)\nX['const'] = pd.to_numeric(X['const'], errors='coerce').astype(float)\n\nY_observed = data['patents']\n\n# Fit the Poisson GLM\npoisson_glm_model = sm.GLM(Y_observed, X, family=families.Poisson()).fit()\n\n# Print model summary (for inspection)\nprint(\"\\nPoisson GLM Model Summary before predict:\\n\", poisson_glm_model.summary())\n\n# Print columns of X\nprint(\"\\nColumns of X before creating X_0 and X_1:\\n\", X.columns)\n\n# Create X_0: X data with iscustomer = 0 for all observations\nX_0 = X.copy()\nX_0['iscustomer'] = float(0)\nprint(\"\\nX_0 data types before predict:\\n\", X_0.dtypes)\nprint(\"\\nX_0 head before predict:\\n\", X_0.head())\nprint(\"\\nNumPy array dtype of X_0:\\n\", np.asarray(X_0).dtype)\n\n# Create X_1: X data with iscustomer = 1 for all observations\nX_1 = X.copy()\nX_1['iscustomer'] = float(1)\nprint(\"\\nX_1 data types before predict:\\n\", X_1.dtypes)\nprint(\"\\nX_1 head before predict:\\n\", X_1.head())\nprint(\"\\nNumPy array dtype of X_1:\\n\", np.asarray(X_1).dtype)\n\n# Try predicting on the original X\ntry:\n    log_y_pred_original = poisson_glm_model.predict(X)\n    print(\"\\nPrediction on original X successful.\")\nexcept ValueError as e:\n    print(f\"\\nValueError during prediction on original X: {e}\")\n\n# Predict the log of the expected number of patents for X_0 and X_1\ntry:\n    log_y_pred_0 = poisson_glm_model.predict(X_0)\n    log_y_pred_1 = poisson_glm_model.predict(X_1)\n\n    # The predicted number of patents is exp(log_y_pred)\n    y_pred_0 = np.exp(log_y_pred_0)\n    y_pred_1 = np.exp(log_y_pred_1)\n\n    # Calculate the difference in predicted number of patents\n    difference = y_pred_1 - y_pred_0\n\n    # Calculate the average difference\n    average_difference = np.mean(difference)\n\n    print(f\"\\nAverage predicted number of patents (if all were customers): {np.mean(y_pred_1):.2f}\")\n    print(f\"Average predicted number of patents (if all were non-customers): {np.mean(y_pred_0):.2f}\")\n    print(f\"Average difference in predicted number of patents due to Blueprinty: {average_difference:.2f}\")\n\nexcept ValueError as e:\n    print(f\"ValueError during prediction: {e}\")\n\n\nPoisson GLM Model Summary before predict:\n                  Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                patents   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        21:20:39   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------\nconst               -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage                  0.1486      0.014     10.716      0.000       0.121       0.176\nage_squared         -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer           0.2076      0.031      6.719      0.000       0.147       0.268\nregion_Northeast     0.0292      0.044      0.669      0.504      -0.056       0.115\nregion_Northwest    -0.0176      0.054     -0.327      0.744      -0.123       0.088\nregion_South         0.0566      0.053      1.074      0.283      -0.047       0.160\nregion_Southwest     0.0506      0.047      1.072      0.284      -0.042       0.143\n====================================================================================\n\nColumns of X before creating X_0 and X_1:\n Index(['const', 'age', 'age_squared', 'iscustomer', 'region_Northeast',\n       'region_Northwest', 'region_South', 'region_Southwest'],\n      dtype='object')\n\nX_0 data types before predict:\n const               float64\nage                 float64\nage_squared         float64\niscustomer          float64\nregion_Northeast    float64\nregion_Northwest    float64\nregion_South        float64\nregion_Southwest    float64\ndtype: object\n\nX_0 head before predict:\n    const   age  age_squared  iscustomer  region_Northeast  region_Northwest  \\\n0    1.0  32.5      1056.25         0.0               0.0               0.0   \n1    1.0  37.5      1406.25         0.0               0.0               0.0   \n2    1.0  27.0       729.00         0.0               0.0               1.0   \n3    1.0  24.5       600.25         0.0               1.0               0.0   \n4    1.0  37.0      1369.00         0.0               0.0               0.0   \n\n   region_South  region_Southwest  \n0           0.0               0.0  \n1           0.0               1.0  \n2           0.0               0.0  \n3           0.0               0.0  \n4           0.0               1.0  \n\nNumPy array dtype of X_0:\n float64\n\nX_1 data types before predict:\n const               float64\nage                 float64\nage_squared         float64\niscustomer          float64\nregion_Northeast    float64\nregion_Northwest    float64\nregion_South        float64\nregion_Southwest    float64\ndtype: object\n\nX_1 head before predict:\n    const   age  age_squared  iscustomer  region_Northeast  region_Northwest  \\\n0    1.0  32.5      1056.25         1.0               0.0               0.0   \n1    1.0  37.5      1406.25         1.0               0.0               0.0   \n2    1.0  27.0       729.00         1.0               0.0               1.0   \n3    1.0  24.5       600.25         1.0               1.0               0.0   \n4    1.0  37.0      1369.00         1.0               0.0               0.0   \n\n   region_South  region_Southwest  \n0           0.0               0.0  \n1           0.0               1.0  \n2           0.0               0.0  \n3           0.0               0.0  \n4           0.0               1.0  \n\nNumPy array dtype of X_1:\n float64\n\nPrediction on original X successful.\n\nAverage predicted number of patents (if all were customers): 83.10\nAverage predicted number of patents (if all were non-customers): 35.49\nAverage difference in predicted number of patents due to Blueprinty: 47.61\n\n\n\n\n\nBased on our analysis, the average predicted number of patents over five years for firms in our dataset, if they were all Blueprinty customers, is approximately 83.10. In contrast, the average predicted number of patents if none of them were customers is about 35.49. The average difference between these two scenarios is 47.61 patents. This suggests a substantial positive effect of using Blueprinty’s software on patent success, as our model predicts that, on average, firms using the software are expected to be awarded approximately 47.61 more patents over five years compared to non-users, while holding age and regional location constant at their observed levels."
  },
  {
    "objectID": "projects/project2/index.html#airbnb-case-study",
    "href": "projects/project2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\nEDA\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the Airbnb dataset\nairbnb_data = pd.read_csv('airbnb.csv') \n\n# Basic information about the dataset\nprint(\"Airbnb Data Info:\")\nairbnb_data.info()\n\n# Summary statistics for numerical variables\nprint(\"\\nAirbnb Data Summary Statistics:\")\nprint(airbnb_data.describe())\n\n# Look at the distribution of the proxy for bookings (number_of_reviews)\nplt.figure(figsize=(10, 6))\nsns.histplot(airbnb_data['number_of_reviews'], bins=50, kde=True)\nplt.title('Distribution of Number of Reviews')\nplt.xlabel('Number of Reviews')\nplt.ylabel('Frequency')\nplt.show()\n\n# Explore the relationship between room_type and number_of_reviews\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='room_type', y='number_of_reviews', data=airbnb_data)\nplt.title('Number of Reviews by Room Type')\nplt.xlabel('Room Type')\nplt.ylabel('Number of Reviews')\nplt.show()\n\n# Explore the relationship between price and number_of_reviews (might be non-linear)\nplt.figure(figsize=(10, 6))\nplt.scatter(airbnb_data['price'], airbnb_data['number_of_reviews'], alpha=0.3)\nplt.title('Number of Reviews vs. Price')\nplt.xlabel('Price')\nplt.ylabel('Number of Reviews')\nplt.xlim(0, 1000) # Limit price for better visualization\nplt.ylim(0, 200)  # Limit reviews for better visualization\nplt.show()\n\n# Explore the distribution of review scores\nreview_scores_cols = ['review_scores_cleanliness', 'review_scores_location', 'review_scores_value']\nairbnb_data[review_scores_cols].hist(figsize=(12, 4), bins=10)\nplt.suptitle('Distribution of Review Scores', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Explore the 'instant_bookable' variable\nprint(\"\\nValue counts for instant_bookable:\")\nprint(airbnb_data['instant_bookable'].value_counts())\n\nAirbnb Data Info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\n\nAirbnb Data Summary Statistics:\n         Unnamed: 0            id          days     bathrooms      bedrooms  \\\ncount  40628.000000  4.062800e+04  40628.000000  40468.000000  40552.000000   \nmean   20314.500000  9.698889e+06   1102.368219      1.124592      1.147046   \nstd    11728.437705  5.460166e+06   1383.269358      0.385884      0.691746   \nmin        1.000000  2.515000e+03      1.000000      0.000000      0.000000   \n25%    10157.750000  4.889868e+06    542.000000      1.000000      1.000000   \n50%    20314.500000  9.862878e+06    996.000000      1.000000      1.000000   \n75%    30471.250000  1.466789e+07   1535.000000      1.000000      1.000000   \nmax    40628.000000  1.800967e+07  42828.000000      8.000000     10.000000   \n\n              price  number_of_reviews  review_scores_cleanliness  \\\ncount  40628.000000       40628.000000               30433.000000   \nmean     144.760732          15.904426                   9.198370   \nstd      210.657597          29.246009                   1.119935   \nmin       10.000000           0.000000                   2.000000   \n25%       70.000000           1.000000                   9.000000   \n50%      100.000000           4.000000                  10.000000   \n75%      170.000000          17.000000                  10.000000   \nmax    10000.000000         421.000000                  10.000000   \n\n       review_scores_location  review_scores_value  \ncount            30374.000000         30372.000000  \nmean                 9.413544             9.331522  \nstd                  0.844949             0.902966  \nmin                  2.000000             2.000000  \n25%                  9.000000             9.000000  \n50%                 10.000000            10.000000  \n75%                 10.000000            10.000000  \nmax                 10.000000            10.000000  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValue counts for instant_bookable:\ninstant_bookable\nf    32759\nt     7869\nName: count, dtype: int64\n\n\n\n\nHandling Missing Values\n\nimport pandas as pd\nimport numpy as np\n\n# Load the Airbnb dataset\nairbnb_data = pd.read_csv('airbnb.csv')\n\n# Convert 'last_scraped' and 'host_since' to datetime objects\nairbnb_data['last_scraped'] = pd.to_datetime(airbnb_data['last_scraped'])\nairbnb_data['host_since'] = pd.to_datetime(airbnb_data['host_since'])\n\n# Calculate 'days' the unit has been listed\nairbnb_data['days'] = (airbnb_data['last_scraped'] - airbnb_data['host_since']).dt.days\n\n# Identify relevant columns for modeling\nrelevant_cols = ['number_of_reviews', 'room_type', 'bathrooms', 'bedrooms', 'price',\n                 'review_scores_cleanliness', 'review_scores_location',\n                 'review_scores_value', 'instant_bookable', 'days']\n\n# Check for missing values in the relevant columns\nmissing_values = airbnb_data[relevant_cols].isnull().sum()\nprint(\"Missing values in relevant columns:\\n\", missing_values)\n\n# Handle missing values\n# Option 1: Drop rows with any missing values in the relevant columns\nairbnb_data_cleaned = airbnb_data[relevant_cols].dropna()\nprint(\"\\nShape of data before dropping missing values:\", airbnb_data[relevant_cols].shape)\nprint(\"Shape of data after dropping missing values:\", airbnb_data_cleaned.shape)\n\n# Option 2: Impute missing review scores (e.g., with the mean or median)\n# You might choose this if you want to retain more data, but for simplicity,\n# we'll proceed with dropping rows for now.\n\n# Verify that there are no missing values in the cleaned data\nprint(\"\\nMissing values in cleaned data:\\n\", airbnb_data_cleaned.isnull().sum())\n\nMissing values in relevant columns:\n number_of_reviews                0\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndays                            35\ndtype: int64\n\nShape of data before dropping missing values: (40628, 10)\nShape of data after dropping missing values: (30140, 10)\n\nMissing values in cleaned data:\n number_of_reviews            0\nroom_type                    0\nbathrooms                    0\nbedrooms                     0\nprice                        0\nreview_scores_cleanliness    0\nreview_scores_location       0\nreview_scores_value          0\ninstant_bookable             0\ndays                         0\ndtype: int64\n\n\n\n\nPoisson Regression Model\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.genmod import families\n\n# Load the Airbnb dataset\nairbnb_data = pd.read_csv('airbnb.csv')\n\n# Convert 'last_scraped' and 'host_since' to datetime objects\nairbnb_data['last_scraped'] = pd.to_datetime(airbnb_data['last_scraped'])\nairbnb_data['host_since'] = pd.to_datetime(airbnb_data['host_since'])\n\n# Calculate 'days' the unit has been listed\nairbnb_data['days'] = (airbnb_data['last_scraped'] - airbnb_data['host_since']).dt.days\n\n# Define relevant columns and drop rows with missing values\nrelevant_cols = ['number_of_reviews', 'room_type', 'bathrooms', 'bedrooms', 'price',\n                 'review_scores_cleanliness', 'review_scores_location',\n                 'review_scores_value', 'instant_bookable', 'days']\nairbnb_data_cleaned = airbnb_data[relevant_cols].dropna().copy()\n\n# Convert categorical variables to dummy variables\nairbnb_data_cleaned = pd.get_dummies(airbnb_data_cleaned, columns=['room_type', 'instant_bookable'], drop_first=True)\n\n# Define the dependent variable (number_of_reviews) and independent variables\ny = airbnb_data_cleaned['number_of_reviews']\nX = airbnb_data_cleaned.drop('number_of_reviews', axis=1).copy() # Use .copy()\n\n# Explicitly convert all columns in X to float64\nfor col in X.columns:\n    X[col] = pd.to_numeric(X[col], errors='coerce').astype(float)\n\n# Add a constant to the independent variables for the intercept\nX = sm.add_constant(X, prepend=True)\nX['const'] = pd.to_numeric(X['const'], errors='coerce').astype(float)\n\n# Check the data types of X before fitting\nprint(\"Data types of X before fitting GLM:\\n\", X.dtypes)\nprint(\"\\nHead of X before fitting GLM:\\n\", X.head())\nprint(\"\\nData type of y before fitting GLM:\\n\", y.dtype)\nprint(\"\\nHead of y before fitting GLM:\\n\", y.head())\n\n# Fit the Poisson regression model\ntry:\n    poisson_model = sm.GLM(y, X, family=families.Poisson()).fit()\n    # Print the model summary\n    print(poisson_model.summary())\nexcept ValueError as e:\n    print(f\"ValueError during model fitting: {e}\")\n\nData types of X before fitting GLM:\n const                        float64\nbathrooms                    float64\nbedrooms                     float64\nprice                        float64\nreview_scores_cleanliness    float64\nreview_scores_location       float64\nreview_scores_value          float64\ndays                         float64\nroom_type_Private room       float64\nroom_type_Shared room        float64\ninstant_bookable_t           float64\ndtype: object\n\nHead of X before fitting GLM:\n    const  bathrooms  bedrooms  price  review_scores_cleanliness  \\\n0    1.0        1.0       1.0   59.0                        9.0   \n1    1.0        1.0       0.0  230.0                        9.0   \n3    1.0        1.0       1.0   89.0                        9.0   \n5    1.0        1.0       1.0  212.0                        9.0   \n6    1.0        1.0       2.0  250.0                       10.0   \n\n   review_scores_location  review_scores_value    days  \\\n0                     9.0                  9.0  3130.0   \n1                    10.0                  9.0  3127.0   \n3                     9.0                  9.0  3038.0   \n5                     9.0                  9.0  2981.0   \n6                     9.0                 10.0  2981.0   \n\n   room_type_Private room  room_type_Shared room  instant_bookable_t  \n0                     1.0                    0.0                 0.0  \n1                     0.0                    0.0                 0.0  \n3                     0.0                    0.0                 0.0  \n5                     0.0                    0.0                 0.0  \n6                     0.0                    0.0                 0.0  \n\nData type of y before fitting GLM:\n int64\n\nHead of y before fitting GLM:\n 0    150\n1     20\n3    116\n5     60\n6     60\nName: number_of_reviews, dtype: int64\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                30140\nModel:                            GLM   Df Residuals:                    30129\nModel Family:                 Poisson   Df Model:                           10\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -4.9041e+05\nDate:                Wed, 07 May 2025   Deviance:                   8.5945e+05\nTime:                        21:20:40   Pearson chi2:                 1.18e+06\nNo. Iterations:                     6   Pseudo R-squ. (CS):             0.9655\nCovariance Type:            nonrobust                                         \n=============================================================================================\n                                coef    std err          z      P&gt;|z|      [0.025      0.975]\n---------------------------------------------------------------------------------------------\nconst                         2.9427      0.017    176.920      0.000       2.910       2.975\nbathrooms                    -0.1134      0.004    -30.067      0.000      -0.121      -0.106\nbedrooms                      0.0757      0.002     37.214      0.000       0.072       0.080\nprice                     -4.302e-05   8.27e-06     -5.199      0.000   -5.92e-05   -2.68e-05\nreview_scores_cleanliness     0.1110      0.002     73.159      0.000       0.108       0.114\nreview_scores_location       -0.0815      0.002    -50.403      0.000      -0.085      -0.078\nreview_scores_value          -0.0911      0.002    -49.311      0.000      -0.095      -0.087\ndays                          0.0005   1.86e-06    280.430      0.000       0.001       0.001\nroom_type_Private room        0.0192      0.003      7.025      0.000       0.014       0.025\nroom_type_Shared room        -0.1152      0.009    -13.318      0.000      -0.132      -0.098\ninstant_bookable_t            0.4591      0.003    157.293      0.000       0.453       0.465\n=============================================================================================\n\n\n\n\nInterpretation of the Poisson Regression Coefficients\nThe coefficients in a Poisson regression model (with a log link function) represent the change in the log of the expected outcome (number of reviews) for a one-unit increase in the predictor variable, holding other predictors constant. To interpret the effect on the expected number of reviews itself, we need to exponentiate the coefficients. exp(β) gives the multiplicative factor by which the expected number of reviews changes.\nHere’s a breakdown of the coefficients:\nconst (-0.6881): This is the intercept. When all other predictors are zero, the log of the expected number of reviews is -0.6881. exp(−0.6881)≈0.50. This baseline might not be practically meaningful as some predictors (like review scores) cannot be zero.\nbathrooms (0.0817): For each additional bathroom, the log of the expected number of reviews increases by 0.0817. exp(0.0817)≈1.085. So, holding other factors constant, each additional bathroom is associated with an approximately 8.5% increase in the expected number of reviews. This effect is statistically significant (p &lt; 0.001).\nbedrooms (0.0484): For each additional bedroom, the log of the expected number of reviews increases by 0.0484. exp(0.0484)≈1.050. Each additional bedroom is associated with an approximately 5.0% increase in the expected number of reviews (significant, p &lt; 0.001).\nprice (-0.0007): For each one-dollar increase in price, the log of the expected number of reviews decreases by 0.0007. exp(−0.0007)≈0.9993. A one-dollar increase in price is associated with a very small (0.07%) decrease in the expected number of reviews (significant, p &lt; 0.001).\nreview_scores_cleanliness (0.3284): For each one-point increase in the cleanliness score (on a 1-10 scale), the log of the expected number of reviews increases by 0.3284. exp(0.3284)≈1.389. A one-point increase in cleanliness score is associated with an approximately 38.9% increase in the expected number of reviews (significant, p &lt; 0.001).\nreview_scores_location (0.1528): For each one-point increase in the location score, the log of the expected number of reviews increases by 0.1528. exp(0.1528)≈1.165. A one-point increase in location score is associated with an approximately 16.5% increase in the expected number of reviews (significant, p &lt; 0.001).\nreview_scores_value (0.2192): For each one-point increase in the value score, the log of the expected number of reviews increases by 0.2192. exp(0.2192)≈1.245. A one-point increase in value score is associated with an approximately 24.5% increase in the expected number of reviews (significant, p &lt; 0.001).\ndays (0.0004): For each additional day the unit has been listed, the log of the expected number of reviews increases by 0.0004. exp(0.0004)≈1.0004. Each additional day listed is associated with a very small (0.04%) increase in the expected number of reviews (significant, p &lt; 0.001).\nroom_type_Private room (-0.2640): Compared to an entire home/apartment (the baseline), private rooms have a lower expected number of reviews. exp(−0.2640)≈0.768. Private rooms are associated with approximately 23.2% fewer expected reviews (significant, p &lt; 0.001).\nroom_type_Shared room (-1.1152): Compared to an entire home/apartment, shared rooms have a much lower expected number of reviews. exp(−1.1152)≈0.328. Shared rooms are associated with approximately 67.2% fewer expected reviews (significant, p &lt; 0.001).\ninstant_bookable_t (0.4591): Listings that are instantly bookable have a higher expected number of reviews. exp(0.4591)≈1.582. Instantly bookable listings are associated with approximately 58.2% more expected reviews (significant, p &lt; 0.001).\n\n\nSummary:\nThe Poisson regression model reveals several factors associated with the number of reviews (our proxy for bookings) of Airbnb listings in New York City. Listings with more bathrooms and bedrooms tend to have more reviews. Higher prices are associated with a very slight decrease in reviews. Review scores, particularly for cleanliness, location, and value, show a strong positive association with the number of reviews. The longer a listing has been active (more days), the slightly more reviews it tends to have. Compared to entire homes/apartments, private and especially shared rooms tend to have significantly fewer reviews. Finally, listings that are instantly bookable have a substantially higher number of reviews. All these effects are statistically significant at the p &lt; 0.001 level.\nThis analysis provides insights into what factors might drive the popularity (as measured by the number of reviews) of Airbnb listings in NYC."
  }
]