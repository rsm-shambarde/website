[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Your Name",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nSumedh Hambarde\nApr 25, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\nFundraisers often rely on rules of thumb rather than scientific evidence to guide their strategies. While the economics of charity has been studied from the “supply” side (e.g., the impact of tax deductions), there are still “critical gaps” in understanding the “demand” side (i.e., how and why donors choose to give).  \nOne common fundraising tool is the matching grant, where a donor pledges to match the contributions of others. Fundraisers often believe that higher matching ratios (e.g., 2:1 or 3:1) are more effective in attracting donations, but there is limited research to support this.\n\n\n\nKarlan and List (2007) aimed to address this gap by examining the impact of matching grants on charitable giving through a large-scale natural field experiment. Specifically, the study investigates whether and to what extent “price” (in the form of matching grant ratios) matters in charitable fundraising.  \n\n\n\nThe experiment was conducted in collaboration with a liberal non-profit organization in the United States that focuses on social and policy issues related to civil liberties. The organization is a 501(c)3 charity, meaning donations are tax-deductible. The organization regularly solicits donations from its prior donors through direct mail campaigns.  \nThe organization’s membership has the following characteristics:\n\nApproximately 70% male\nApproximately 60% over 65 years old\nApproximately 80% with a college education\nPolitical leaning: 85% voted for Gore in the 2000 presidential election\n\n\n\n\nThe researchers conducted a natural field experiment using a direct mail solicitation to over 50,000 past donors of the organization. Individuals were randomly assigned to either a treatment group that received a matching grant offer or a control group that did not. The treatment group was further randomized to receive different matching grant ratios.\n\n\n\nAll participants received a four-page fundraising letter.  \nControl Group: Received a standard letter with no mention of a matching grant.   Treatment Groups: Received a letter that included an additional paragraph announcing the matching grant offer. The matching grant had different price ratios: 1:1 match: For every dollar donated, the organization receives two dollars.   2:1 match: For every dollar donated, the organization receives three dollars.   3:1 match: For every dollar donated, the organization receives four dollars."
  },
  {
    "objectID": "projects/project1/index.html#introduction",
    "href": "projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\n\n\nFundraisers often rely on rules of thumb rather than scientific evidence to guide their strategies. While the economics of charity has been studied from the “supply” side (e.g., the impact of tax deductions), there are still “critical gaps” in understanding the “demand” side (i.e., how and why donors choose to give).  \nOne common fundraising tool is the matching grant, where a donor pledges to match the contributions of others. Fundraisers often believe that higher matching ratios (e.g., 2:1 or 3:1) are more effective in attracting donations, but there is limited research to support this.\n\n\n\nKarlan and List (2007) aimed to address this gap by examining the impact of matching grants on charitable giving through a large-scale natural field experiment. Specifically, the study investigates whether and to what extent “price” (in the form of matching grant ratios) matters in charitable fundraising.  \n\n\n\nThe experiment was conducted in collaboration with a liberal non-profit organization in the United States that focuses on social and policy issues related to civil liberties. The organization is a 501(c)3 charity, meaning donations are tax-deductible. The organization regularly solicits donations from its prior donors through direct mail campaigns.  \nThe organization’s membership has the following characteristics:\n\nApproximately 70% male\nApproximately 60% over 65 years old\nApproximately 80% with a college education\nPolitical leaning: 85% voted for Gore in the 2000 presidential election\n\n\n\n\nThe researchers conducted a natural field experiment using a direct mail solicitation to over 50,000 past donors of the organization. Individuals were randomly assigned to either a treatment group that received a matching grant offer or a control group that did not. The treatment group was further randomized to receive different matching grant ratios.\n\n\n\nAll participants received a four-page fundraising letter.  \nControl Group: Received a standard letter with no mention of a matching grant.   Treatment Groups: Received a letter that included an additional paragraph announcing the matching grant offer. The matching grant had different price ratios: 1:1 match: For every dollar donated, the organization receives two dollars.   2:1 match: For every dollar donated, the organization receives three dollars.   3:1 match: For every dollar donated, the organization receives four dollars."
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nimport pandas as pd\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n#print(data.head())\n\nprint(data.info())\n\nprint(data.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168560      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378105     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258633  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\n\nBalance Tests: Checking the success of randomization\nIn any experiment that uses random assignment, it’s crucial to verify that the randomization process was successful in creating comparable groups. This ensures that any differences I observe in donation behavior are likely due to the matching grant offers and not simply due to pre-existing differences between the groups. To do this, I conducted balance tests on several pre-treatment variables.\n\nMethodology\nTo assess the balance between the treatment and control groups, I performed two types of statistical tests for each pre-treatment variable:\n\nT-tests: I used independent samples t-tests to compare the means of each variable between the treatment and control groups. The null hypothesis for each t-test was that there is no difference in the average value of the variable between the two groups.\nLinear Regressions: I also ran a series of simple linear regressions. In each regression, the pre-treatment variable was the dependent variable, and the treatment assignment (coded as 0 for control and 1 for treatment) was the independent variable. This allowed me to estimate the average difference in the pre-treatment variable between the treatment and control groups.\n\nIt’s important to note that, as the professor emphasized, the t-test and the regression approach are two ways of examining the same thing and should give me very similar results.\n\n\nResults\nI conducted these balance tests on the following pre-treatment variables:\n\nMonths since last donation\nNumber of prior donations\nFemale (an indicator variable for gender)\nCouple (an indicator variable for whether the individual is part of a couple)\n\nThe code for this, as well as the results from the balance tests are as follows:\n\nimport pandas as pd\nfrom scipy import stats\nimport statsmodels.formula.api as sm\nimport numpy as np\n\n# Load your data\ndata = pd.read_stata('dataverse_files/AER merged.dta')  # Or pd.read_csv(), etc.\n\n#print(data[['treatment', 'control']].head(2))\ndef test_balance(var_value, var_name):\n\n    print('\\n')\n    variable_to_test = var_value\n\n    # T-test\n    control_group = data[data['control'] == 1][variable_to_test]\n    treatment_group = data[data['treatment'] == 1][variable_to_test]\n    #print(treatment_group.head(2))\n    #print(control_group.head(2))\n\n    # Calculate means\n    mean_control = np.mean(control_group)\n    mean_treatment = np.mean(treatment_group)\n\n    # Calculate variances\n    variance_control = np.var(control_group, ddof=1)  # ddof=1 for sample variance\n    variance_treatment = np.var(treatment_group, ddof=1)\n\n    # Calculate sample sizes\n    n_control = len(control_group)\n    n_treatment = len(treatment_group)\n\n    # Calculate pooled variance\n    pooled_variance = ((n_treatment - 1) * variance_treatment + (n_control - 1) * variance_control) / (n_treatment + n_control - 2)\n\n    # Calculate pooled standard error\n    pooled_standard_error = np.sqrt(pooled_variance * (1 / n_treatment + 1 / n_control))\n\n    # Calculate t-statistic\n    t_statistic_manual = (mean_treatment - mean_control) / pooled_standard_error\n    print(f\"t-statistic for {var_name}: t = {t_statistic_manual:.3f}\")\n\n    df = n_treatment + n_control - 2\n\n    p_value_manual_two_tailed = stats.t.sf(abs(t_statistic_manual), df) * 2\n\n    print(f\"Two-Tailed p-value: {p_value_manual_two_tailed:.3f}\")\n\n\n\n    # Linear Regression\n    formula = f'{variable_to_test} ~ treatment'\n    model = sm.ols(formula, data=data).fit()\n    p_value_reg = model.pvalues['treatment']\n    print(f\"Regression for {var_name}: p = {p_value_reg:.3f}\")\n\n    # Interpretation\n    if p_value_manual_two_tailed &lt; 0.05:\n        print(f\"For {var_name}, there is a statistically significant difference between treatment and control groups.\")\n    else:\n        print(f\"For {var_name}, there is no statistically significant difference between treatment and control groups.\")\n\n\ntest_balance('mrm2', 'Months since last donation')\ntest_balance('freq', 'Number of Prior Donations')\n#test_balance('perbush', 'State vote share for Bush')\n#test_balance('cases', 'Court cases from 2004-05 in which organization was involved')\ntest_balance('female', 'Female')\ntest_balance('couple', 'Couple')\n# Repeat for other variables\n\n\n\nt-statistic for Months since last donation: t = 0.119\nTwo-Tailed p-value: 0.905\nRegression for Months since last donation: p = 0.905\nFor Months since last donation, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Number of Prior Donations: t = -0.111\nTwo-Tailed p-value: 0.912\nRegression for Number of Prior Donations: p = 0.912\nFor Number of Prior Donations, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Female: t = -1.778\nTwo-Tailed p-value: 0.075\nRegression for Female: p = 0.079\nFor Female, there is no statistically significant difference between treatment and control groups.\n\n\nt-statistic for Couple: t = -0.590\nTwo-Tailed p-value: 0.555\nRegression for Couple: p = 0.559\nFor Couple, there is no statistically significant difference between treatment and control groups.\n\n\n\n\nOverall Assessment of Randomization\nBased on these balance tests, I conclude that the randomization process in the Karlan and List (2007) experiment appears to have been largely successful. For all four pre-treatment variables I examined, I did not find statistically significant differences between the treatment and control groups at the 0.05 significance level.\nWhile some minor differences are expected due to chance, especially in large samples, the general lack of statistical significance suggests that the treatment and control groups are indeed comparable. This strengthens the internal validity of the study and supports the authors’ ability to attribute any observed differences in donation behavior to the matching grant offers.\n\n\nImportance of Balance Tests\nBalance tests are a critical component of any experimental study, and Karlan and List (2007) included them for good reason. These tests serve several important purposes:\n\nEstablishing Internal Validity: They provide evidence that the treatment, rather than pre-existing differences, is the likely cause of any observed effects.\nSupporting Causal Inference: They justify making causal claims about the impact of the treatment.\nEnsuring Rigor: They demonstrate the rigor of the experimental design and increase confidence in the study’s findings.\nPromoting Transparency: They allow other researchers to assess the quality of the experiment and attempt to replicate the results."
  },
  {
    "objectID": "projects/project1/index.html#experimental-results",
    "href": "projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nBarplot for proportion of people who donated\n\nimport pandas as pd\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\nimport plotly.graph_objects as go\n\ndef plot_donation_by_group(data):\n    # 2. Calculate donation proportions\n    proportion_gave_treatment = data[data['treatment'] == 1]['gave'].mean()\n    proportion_gave_control = data[data['control'] == 1]['gave'].mean()\n\n    # 3. Prepare data for plotting\n    plot_data = pd.DataFrame({\n        'group': ['Treatment', 'Control'],\n        'proportion_gave': [proportion_gave_treatment, proportion_gave_control]\n    })\n\n    # 4. Create the bar plot\n    fig = go.Figure(data=[\n        go.Bar(x=plot_data['group'], y=plot_data['proportion_gave'])\n    ])\n\n    fig.add_trace(go.Scatter(\n        x=plot_data['group'],\n        y=plot_data['proportion_gave'],\n        text=[f\"{100 * p:.2f}%\" for p in plot_data['proportion_gave']],  # Format proportions\n        mode='text',\n        textposition='top center'\n    ))\n    # 5. Customize the plot\n    fig.update_layout(\n        title='Proportion of Donors by Group',\n        xaxis_title='Group',\n        yaxis_title='Proportion Donated',\n        yaxis_range=[0, max(plot_data['proportion_gave']) * 1.1]  # Extend y-axis slightly\n    )\n\n    # 6. Display the plot\n    fig.show()\n\n\nplot_donation_by_group(data)\n\n                                                \n\n\nThe results of my analysis show that the treatment group, which received the matching grant offer, had a higher donation rate (2.2%) compared to the control group (1.79%). This suggests that the matching grant may have had a positive impact on the likelihood of individuals making a donation. However, it’s important to keep in mind that this is just a preliminary observation, and further statistical testing is needed to determine if this difference is statistically significant.\n\n\nBinary donation outcome: t-test and it’s interpretation:\n\nimport pandas as pd\nfrom scipy import stats  # For t-test\n\ndef perform_t_test_on_donation(data):\n    \"\"\"\n    Performs an independent samples t-test on the binary donation outcome.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'treatment', 'control', and 'gave' columns.\n\n    Returns:\n        tuple: (t-statistic, p-value)\n    \"\"\"\n    # --- T-test ---\n    treatment_gave = data[data['treatment'] == 1]['gave']\n    control_gave = data[data['control'] == 1]['gave']\n    t_statistic, p_value_ttest = stats.ttest_ind(treatment_gave, control_gave)\n\n    return t_statistic, p_value_ttest\n\n\nif __name__ == '__main__':\n    # --- Load Your Actual Data Here ---\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with your data loading\n\n    t_statistic, p_value = perform_t_test_on_donation(data)\n\n    print(\"--- T-test Results ---\")\n    print(f\"T-statistic: {t_statistic:.3f}\")\n    print(f\"P-value: {p_value:.3f}\")\n\n    # You would then proceed to interpret these results\n\n--- T-test Results ---\nT-statistic: 3.101\nP-value: 0.002\n\n\n\n\nInterpretation of the t-test:\nThe t-test results indicate a statistically significant difference in donation behavior between the group that received the matching grant offer (the treatment group) and the group that did not (the control group). The p-value of 0.002 is substantially lower than the typical significance level of 0.05, meaning that the observed difference is unlikely to have occurred by chance alone. In other words, there’s strong evidence to suggest that the matching grant offer had a real effect on whether people decided to donate.\nThe positive t-statistic (3.101) suggests that the treatment group had a higher donation rate. This finding aligns with the idea that individuals respond to price-like incentives, even in charitable giving. The matching grant effectively reduces the ‘cost’ of giving; for every dollar a person donates, the charity receives more. This increased ‘bang for your buck’ appears to motivate people to be more generous.\nFrom a behavioral perspective, this result highlights that while altruism and a desire to support a cause are important motivators for charitable giving, financial incentives can also play a significant role. People seem to weigh the perceived value of their contribution, and matching grants can significantly shift that calculation. This underscores the potential effectiveness of matching grant campaigns as a fundraising strategy.\n\n\nProbit regression: Results and interpretation\n\nimport pandas as pd\nimport statsmodels.api as sm  # For Probit regression\n\ndef perform_probit_regression(data):\n    \"\"\"\n    Performs a probit regression to model the probability of donation.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'treatment', 'control', and 'gave' columns.\n\n    Returns:\n        sm.ProbitResults: The results of the probit regression.\n    \"\"\"\n\n    # --- Verify that 'treatment' and 'control' are mutually exclusive ---\n    # --- Create treatment dummy variable ---\n    data['treatment_dummy'] = data['treatment']  # Assuming 'treatment' is 1/0\n\n    # --- Probit Regression ---\n    formula = 'gave ~ treatment_dummy'\n    probit_model = sm.Probit(data['gave'], sm.add_constant(data['treatment_dummy']))\n    probit_results = probit_model.fit()\n\n    return probit_results\n\n\nif __name__ == '__main__':\n    data = pd.read_stata('dataverse_files/AER merged.dta')\n    probit_results = perform_probit_regression(data)\n    \n    # --- Print Results Summary ---\n    print(probit_results.summary())\n\n    # --- Access specific results ---\n    print(\"\\nProbit Regression Results:\")\n    print(f\"Coefficient on treatment: {probit_results.params['treatment_dummy']:.4f}\")\n    print(f\"P-value on treatment: {probit_results.pvalues['treatment_dummy']:.4f}\")\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Fri, 25 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        02:12:18   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n===================================================================================\n                      coef    std err          z      P&gt;|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nconst              -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment_dummy     0.0868      0.028      3.113      0.002       0.032       0.141\n===================================================================================\n\nProbit Regression Results:\nCoefficient on treatment: 0.0868\nP-value on treatment: 0.0019\n\n\n\n\nInterpretation of the results:\nThe probit regression results indicate a statistically significant positive effect of the matching grant offer on the probability of making a charitable donation. The coefficient on the treatment_dummy variable is 0.0868, and it has a p-value of 0.002, which is well below the conventional significance level of 0.05. This suggests that being offered a matching grant significantly increased the likelihood that an individual would donate.\nTo understand the magnitude of this effect, we need to consider that the coefficients in a probit regression represent the change in the z-score of the standard normal distribution associated with a one-unit change in the predictor variable (in this case, going from the control group to the treatment group). While the coefficient itself isn’t a direct measure of the change in probability, its positive and statistically significant value clearly demonstrates that the matching offer had a positive impact on the propensity to give.\nIn behavioral terms, this finding reinforces the idea that the ‘price’ mechanism introduced by the matching grant influences donation decisions. The offer of having their donation matched appears to have provided an additional incentive, nudging individuals who received the treatment letter towards donating at a higher rate than those in the control group who did not receive such an offer. This aligns with economic theories suggesting that individuals respond to incentives, even in the realm of altruistic behavior.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\nPairwise t-tests: Results\n\nimport pandas as pd\nfrom scipy import stats  # For t-test\n\ndef compare_donation_rates_by_ratio(data):\n    \"\"\"\n    Compares donation rates across different match ratios using t-tests.\n\n    Args:\n        data (pd.DataFrame): DataFrame with 'ratio' and 'gave' columns.\n\n    Returns:\n        dict: A dictionary containing the t-test results for each comparison.\n    \"\"\"\n\n    results = {}\n\n    # 1:1 vs. 2:1\n    gave_1 = data[data['ratio'] == 1]['gave']\n    gave_2 = data[data['ratio'] == 2]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_1, gave_2)\n    results['1:1 vs. 2:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    # 1:1 vs. 3:1\n    gave_1 = data[data['ratio'] == 1]['gave']\n    gave_3 = data[data['ratio'] == 3]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_1, gave_3)\n    results['1:1 vs. 3:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    # 2:1 vs. 3:1\n    gave_2 = data[data['ratio'] == 2]['gave']\n    gave_3 = data[data['ratio'] == 3]['gave']\n    t_stat, p_value = stats.ttest_ind(gave_2, gave_3)\n    results['2:1 vs. 3:1'] = {'t_statistic': t_stat, 'p_value': p_value}\n\n    return results\n\n\nif __name__ == '__main__':\n    # --- Load Your Actual Data Here ---\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with your data loading\n\n    results = compare_donation_rates_by_ratio(data)\n\n    # --- Print Results ---\n    print(\"T-test Results: Donation Rates by Match Ratio\")\n    for comparison, values in results.items():\n        print(f\"\\nComparison: {comparison}\")\n        print(f\"  T-statistic: {values['t_statistic']:.3f}\")\n        print(f\"  P-value: {values['p_value']:.3f}\")\n\nT-test Results: Donation Rates by Match Ratio\n\nComparison: 1:1 vs. 2:1\n  T-statistic: -0.965\n  P-value: 0.335\n\nComparison: 1:1 vs. 3:1\n  T-statistic: -1.015\n  P-value: 0.310\n\nComparison: 2:1 vs. 3:1\n  T-statistic: -0.050\n  P-value: 0.960\n\n\n\n\nPairwise t-tests: Interpretation:\nLack of Statistical Significance:\n\nFor all three comparisons, the p-values are considerably greater than the common significance level of 0.05.\nThis means that we fail to reject the null hypothesis in each case. The null hypothesis states that there is no difference in the average donation rates between the two groups being compared.\nIn simpler terms, the data does not provide enough evidence to conclude that changing the match ratio (from 1:1 to 2:1, from 1:1 to 3:1, or from 2:1 to 3:1) has a statistically significant impact on the proportion of people who donate.\nThese results match the conclusions made in the original research publication.\n\nBehavioral Implications:\n\nThese findings might suggest that, within the range of match ratios tested, the specific generosity of the match offer doesn’t strongly influence the likelihood of donating.\nIt’s possible that the presence of any match is more important than the size of the match. People might be motivated by the simple fact that their donation will be multiplied, without being very sensitive to the exact multiplication factor.\nAnother possibility is that the differences in match ratios tested were not large enough to elicit a statistically detectable change in behavior.\n\n\nimport statsmodels.formula.api as sm  # For OLS regression\n\nimport pandas as pd\ndata = pd.read_stata('dataverse_files/AER merged.dta')\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\n# --- Regression ---\nformula = 'gave ~ ratio1 + ratio2 + ratio3'\nmodel = sm.ols(formula, data=data).fit()\n\n# --- Print Results Summary ---\nprint(model.summary())\n\n# --- Interpretation ---\nprint(\"\\nRegression Results Interpretation:\")\nprint(\"----------------------------\")\n\nprint(f\"Coefficient for ratio1: {model.params['ratio1']:.4f}\")\nprint(f\"P-value for ratio1: {model.pvalues['ratio1']:.4f}\")\n\nprint(f\"Coefficient for ratio2: {model.params['ratio2']:.4f}\")\nprint(f\"P-value for ratio2: {model.pvalues['ratio2']:.4f}\")\n\nprint(f\"Coefficient for ratio3: {model.params['ratio3']:.4f}\")\nprint(f\"P-value for ratio3: {model.pvalues['ratio3']:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Fri, 25 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        02:12:19   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nRegression Results Interpretation:\n----------------------------\nCoefficient for ratio1: 0.0029\nP-value for ratio1: 0.0966\nCoefficient for ratio2: 0.0048\nP-value for ratio2: 0.0061\nCoefficient for ratio3: 0.0049\nP-value for ratio3: 0.0051\n\n\nInterpretation of the OLS Regression Results\nIn this OLS regression, we modeled the binary outcome of whether a donation was made (gave) as a function of dummy variables representing the different match ratios (ratio1 for 1:1, ratio2 for 2:1, and ratio3 for 3:1). The “Control” group (no match) serves as the implicit reference category.\nHere’s a breakdown of the key findings:\nIntercept (Coefficient: 0.0179, P-value: 0.000): The intercept represents the predicted probability of donation for the reference group, which is the “Control” group (where ratio1, ratio2, and ratio3 are all 0). A coefficient of 0.0179 suggests that in the absence of any matching offer, the predicted donation rate is approximately 1.79%. This is statistically significant (p &lt; 0.001).\nCoefficient for ratio1 (0.0029, P-value: 0.097): This coefficient estimates the additional change in the probability of donation when the match ratio is 1:1, compared to the Control group. The positive coefficient (0.0029) suggests that the 1:1 match is associated with a 0.29 percentage point increase in the predicted donation rate (1.79% + 0.29% = 2.08%). However, the p-value of 0.097 is greater than the conventional significance level of 0.05. Therefore, we do not have statistically significant evidence that the 1:1 matching offer significantly increased donations compared to the control group in this OLS model.\nCoefficient for ratio2 (0.0048, P-value: 0.006): This coefficient estimates the additional change in the probability of donation when the match ratio is 2:1, compared to the Control group. The positive and statistically significant coefficient (0.0048, p = 0.006) indicates that the 2:1 matching offer led to a significant increase of 0.48 percentage points in the predicted donation rate compared to the Control group (1.79% + 0.48% = 2.27%).\nCoefficient for ratio3 (0.0049, P-value: 0.005): This coefficient estimates the additional change in the probability of donation when the match ratio is 3:1, compared to the Control group. The positive and statistically significant coefficient (0.0049, p = 0.005) shows that the 3:1 matching offer resulted in a significant increase of 0.49 percentage points in the predicted donation rate compared to the Control group (1.79% + 0.49% = 2.28%).\nOverall Interpretation:\nThe OLS regression results suggest that while a 1:1 matching offer did not significantly increase donation rates compared to no offer, both the 2:1 and 3:1 matching offers had a statistically significant positive impact on the likelihood of donation. The magnitudes of the effects for the 2:1 and 3:1 matches are quite similar, suggesting that increasing the match ratio beyond 2:1 might not lead to a substantial further increase in the proportion of donors.\nThese findings are broadly consistent with the idea that matching grants incentivize charitable giving. The stronger effects observed for the higher match ratios (2:1 and 3:1) provide some evidence that the “price” of giving matters, with a more generous match leading to a greater increase in donation propensity compared to no match. However, the lack of a significant effect for the 1:1 match hints at a possible threshold effect or a weaker influence at that particular ratio in this model.\n\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\ndef calculate_direct_response_rate_differences(data):\n    \"\"\"Calculates response rate differences directly from data.\"\"\"\n    prop_1 = data[data['ratio'] == 1]['gave'].mean()\n    prop_2 = data[data['ratio'] == 2]['gave'].mean()\n    prop_3 = data[data['ratio'] == 3]['gave'].mean()\n    return {\n        '1:1 vs. 2:1': prop_2 - prop_1,\n        '2:1 vs. 3:1': prop_3 - prop_2,\n        '1:1 vs. 3:1': prop_3 - prop_1  # Added comparison\n    }\n\ndef regress_and_get_coefficient_differences(data):\n    \"\"\"Regresses 'gave' on ratio dummies and returns coefficient differences.\"\"\"\n    formula = 'gave ~ ratio1 + ratio2 + ratio3'\n    model = sm.ols(formula, data=data).fit()\n    return {\n        '1:1 vs. 2:1': model.params['ratio2'] - model.params['ratio1'],\n        '2:1 vs. 3:1': model.params['ratio3'] - model.params['ratio2'],\n        '1:1 vs. 3:1': model.params['ratio3'] - model.params['ratio1']  # Added comparison\n    }\n\nif __name__ == '__main__':\n    data = pd.read_stata('dataverse_files/AER merged.dta')  # Replace with actual data loading\n    data['ratio1'] = (data['ratio'] == 1).astype(int)\n    data['ratio2'] = (data['ratio'] == 2).astype(int)\n    data['ratio3'] = (data['ratio'] == 3).astype(int)\n\n    direct_diffs = calculate_direct_response_rate_differences(data)\n    regression_diffs = regress_and_get_coefficient_differences(data)\n\n    print(\"Response Rate Differences:\")\n    for key in direct_diffs:\n        print(f\"  {key}: Direct = {direct_diffs[key]:.4f}, Regression = {regression_diffs[key]:.4f}\")\n\n    # Interpretation\n    print(\"\\nInterpretation:\")\n    print(\"--------------------\")\n\n    # Example: Compare the direct and regression differences\n    print(\"Comparison of Direct and Regression Differences:\")\n    for key in direct_diffs:\n        print(f\"  {key}: Difference = {abs(direct_diffs[key] - regression_diffs[key]):.4f}\")\n\n    # Draw conclusions about effectiveness\n    # ... (Your conclusions here based on the compared differences)\n\nResponse Rate Differences:\n  1:1 vs. 2:1: Direct = 0.0019, Regression = 0.0019\n  2:1 vs. 3:1: Direct = 0.0001, Regression = 0.0001\n  1:1 vs. 3:1: Direct = 0.0020, Regression = 0.0020\n\nInterpretation:\n--------------------\nComparison of Direct and Regression Differences:\n  1:1 vs. 2:1: Difference = 0.0000\n  2:1 vs. 3:1: Difference = 0.0000\n  1:1 vs. 3:1: Difference = 0.0000\n\n\nThe direct calculations and the differences in regression coefficients yield very similar results. The response rate (proportion donating) increases as the match ratio increases. However, the magnitude of these increases is quite small. The largest difference is between the 1:1 and 3:1 match rates, with a 0.20 percentage point increase in the likelihood of donation. The increase from 1:1 to 2:1 is 0.19 percentage points, and the increase from 2:1 to 3:1 is only 0.01 percentage points.\nConclusion on Effectiveness:\nWhile there is a trend suggesting that higher match ratios lead to slightly higher donation rates, the small magnitude of these differences, especially the minimal increase from a 2:1 to a 3:1 match, indicates diminishing returns in the effectiveness of increasing the match ratio beyond a certain point. The initial introduction of a match (compared to no match, as seen in the regression intercept) appears to have a more substantial impact than incrementally increasing the generosity of the match.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nimport pandas as pd\nfrom scipy import stats  \n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n# --- Filter data for treatment and control groups ---\ntreatment_amount = data[data['treatment'] == 1]['amount']\ncontrol_amount = data[data['control'] == 1]['amount']\n\n# --- Perform t-test ---\nt_statistic, p_value = stats.ttest_ind(treatment_amount, control_amount)\n\n# --- Print Results ---\nprint(\"T-test Results: Donation Amount by Treatment Status\")\nprint(f\"  T-statistic: {t_statistic:.3f}\")\nprint(f\"  P-value: {p_value:.3f}\")\n\nT-test Results: Donation Amount by Treatment Status\n  T-statistic: 1.861\n  P-value: 0.063\n\n\n\nInterpretation:\nThe t-test comparing average donation amounts between the treatment and control groups yielded a t-statistic of 1.861 and a p-value of 0.063. This p-value is slightly above the conventional significance level of 0.05.\nTherefore, we do not have strong statistical evidence to conclude that the matching grant offer significantly affected the average amount donated. While the t-statistic suggests a trend towards a higher donation amount in the treatment group, the result is not statistically significant at the 0.05 level.\nIn simpler terms, the data doesn’t provide conclusive evidence that the matching grant changed how much people gave, on average. It’s important to remember that ‘not significant’ doesn’t mean ‘no effect’; it simply means we can’t rule out that the observed difference occurred by chance.\nFurther analysis or a larger sample size might be needed to determine if a real, but subtle, effect exists. This result suggests that the matching grant primarily influenced whether people donated (as shown in previous analyses) rather than dramatically altering the size of individual donations.\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation? ####\n\nimport pandas as pd\nimport statsmodels.formula.api as sm\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\ndonors_data = data[data['gave'] == 1]\n\n# --- Regression on Donors Only ---\nformula_donors = 'amount ~ treatment + ratio2 + ratio3'  # amount as dependent\nmodel_donors = sm.ols(formula_donors, data=donors_data).fit()\n\n# --- Print Results Summary ---\nprint(model_donors.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.002\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.6171\nDate:                Fri, 25 Apr 2025   Prob (F-statistic):              0.604\nTime:                        02:12:19   Log-Likelihood:                -5326.1\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1030   BIC:                         1.068e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.424     18.788      0.000      40.784      50.297\ntreatment     -0.3974      3.668     -0.108      0.914      -7.595       6.800\nratio2         0.1944      3.812      0.051      0.959      -7.285       7.674\nratio3        -3.8911      3.808     -1.022      0.307     -11.363       3.581\n==============================================================================\nOmnibus:                      583.474   Durbin-Watson:                   2.036\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5502.639\nSkew:                           2.449   Prob(JB):                         0.00\nKurtosis:                      13.184   Cond. No.                         5.53\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nRegression Analysis of Donation Amounts (Among Donors)\nThis analysis examines the factors influencing the amount donated, focusing only on individuals who made a positive contribution. The OLS regression includes the treatment status (treatment) and the dummy variables for the 2:1 (ratio2) and 3:1 (ratio3) match ratios, with the 1:1 match ratio being the implicit reference category among the match conditions.\nThe intercept of 45.5403 suggests that, for those in the control group who donated, the average donation amount was approximately $45.54. This is statistically significant.\nThe coefficient for the treatment variable is -0.3974 and is not statistically significant (p = 0.914). This indicates that, among those who donated, there is no statistically significant difference in the average donation amount between individuals who received a matching offer (the treatment group) and those who did not (the control group).\nSimilarly, the coefficients for ratio2 (0.1944, p = 0.959) and ratio3 (-3.8911, p = 0.307) are also not statistically significant. This suggests that, among donors, there is no statistically significant difference in the average donation amount between those who received a 2:1 match offer compared to those who received a 1:1 match offer, and no significant difference between those who received a 3:1 match offer compared to those who received a 1:1 match offer.\nCausal Interpretation of the Treatment Coefficient:\nYes, the coefficient for the treatment variable can be interpreted causally for the subpopulation of individuals who decided to donate. Because the initial assignment to treatment and control groups was random, any systematic differences in the average donation amount among those who donated can likely be attributed to the effect of the treatment.\nHowever, it’s crucial to remember that this analysis is conditional on someone having already decided to donate. It doesn’t tell us about the causal effect of the treatment on the decision to donate (which we analyzed earlier). This coefficient specifically addresses the impact of the matching offer on the amount given, given that a donation occurred. The lack of a significant effect here suggests that the matching offer primarily influenced the extensive margin (whether to donate) rather than the intensive margin (how much to donate), at least at a statistically detectable level within this sample of donors.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_stata('dataverse_files/AER merged.dta')\n\n# --- Filter data for donors only ---\ndonors_data = data[data['gave'] == 1]\n\n# --- Separate data for treatment and control groups among donors ---\ntreatment_donors = donors_data[donors_data['treatment'] == 1]['amount']\ncontrol_donors = donors_data[donors_data['control'] == 1]['amount']\n\n# --- Calculate average donation amounts ---\navg_treatment_donation = treatment_donors.mean()\navg_control_donation = control_donors.mean()\n\n# --- Create the plots ---\nplt.figure(figsize=(12, 6))  # Adjust figure size as needed\n\n# Plot for Treatment Group\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\nplt.hist(treatment_donors, bins=20, alpha=0.7, color='blue')  # Adjust bins as needed\nplt.axvline(avg_treatment_donation, color='red', linestyle='dashed', linewidth=2)  # Add vertical line for average\nplt.title('Donation Amounts - Treatment Group (Donors Only)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.text(avg_treatment_donation + 5, plt.ylim()[1] * 0.9, f\"Avg: {avg_treatment_donation:.2f}\", color='red') #add text\n\n# Plot for Control Group\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\nplt.hist(control_donors, bins=20, alpha=0.7, color='green')  # Adjust bins as needed\nplt.axvline(avg_control_donation, color='red', linestyle='dashed', linewidth=2)  # Add vertical line for average\nplt.title('Donation Amounts - Control Group (Donors Only)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Frequency')\nplt.text(avg_control_donation + 5, plt.ylim()[1] * 0.9, f\"Avg: {avg_control_donation:.2f}\", color='red') #add text\n\nplt.tight_layout()  # Adjust layout to prevent overlap\nplt.show()"
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- Parameters ---\nn_simulations = 10000  # Number of simulated draws\np_control = 0.018     # Probability of donation in the control group\np_treatment = 0.022   # Probability of donation in the treatment group\n\n# --- Simulate Data ---\ncontrol_group = np.random.binomial(1, p_control, n_simulations)  # 1 for donate, 0 for not donate\ntreatment_group = np.random.binomial(1, p_treatment, n_simulations)\n\n# --- Calculate Differences ---\ndifferences = treatment_group - control_group\n\n# --- Calculate Cumulative Average of Differences ---\ncumulative_avg_diff = np.cumsum(differences) / np.arange(1, n_simulations + 1)\n\n# --- Plotting ---\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg_diff)\nplt.axhline(p_treatment - p_control, color='red', linestyle='--', label='True Treatment Effect')  # True effect line\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers Simulation')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# --- Explanation for the reader ---\n\n\n\n\n\n\n\n\nThis chart demonstrates the Law of Large Numbers in the context of our simulated donation experiment. We simulated 10,000 “individuals” in both a control group (donation probability of 0.018) and a treatment group (donation probability of 0.022). For each simulated individual, we determined whether they donated (1) or not (0) using a random draw from a Bernoulli distribution.\nThe blue line in the chart shows the cumulative average difference in donation rates between the treatment and control groups as we include more and more simulated individuals. Initially, with only a few simulations, the average difference is quite variable (“noisy”) because random fluctuations have a large impact.\nHowever, as we simulate more and more individuals, the cumulative average difference converges towards the true treatment effect, which is 0.004 (0.022 - 0.018). This is shown by the red dashed line.\nThe Law of Large Numbers tells us that as the sample size increases, the sample average will approach the true population average. In our simulation, the average difference in donation rates eventually settles down to the true difference in donation probabilities between the treatment and control groups. This illustrates that with a sufficiently large sample, we can accurately estimate the true effect of the treatment.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- Parameters ---\nn_simulations = 1000  # Number of simulations (repetitions)\nsample_sizes = [50, 200, 500, 1000]  # Sample sizes for the histograms\np_control = 0.018  # Probability of donation in the control group\np_treatment = 0.022  # Probability of donation in the treatment group\n\n# --- Function to simulate and calculate average differences ---\ndef simulate_avg_diff(sample_size, p_control, p_treatment, n_simulations):\n    avg_differences = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, sample_size)\n        treatment_sample = np.random.binomial(1, p_treatment, sample_size)\n        avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n        avg_differences.append(avg_diff)\n    return avg_differences\n\n# --- Create the plots ---\nplt.figure(figsize=(12, 8))\nfor i, sample_size in enumerate(sample_sizes):\n    avg_diffs = simulate_avg_diff(sample_size, p_control, p_treatment, n_simulations)\n    plt.subplot(2, 2, i + 1)\n    plt.hist(avg_diffs, bins=20, alpha=0.7, color='purple')  # Adjust bins as needed\n    plt.title(f'Sample Size = {sample_size}')\n    plt.xlabel('Average Difference')\n    plt.ylabel('Frequency')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis series of four histograms illustrates the Central Limit Theorem. For each histogram, we simulated 1000 experiments. In each experiment, we drew samples from both the control group (donation probability 0.018) and the treatment group (donation probability 0.022) and calculated the difference in the average donation rates between the two groups. We then plotted the distribution of these 1000 average differences.\n\nSample Size = 50: The first histogram shows the distribution of average differences when we draw samples of size 50 from each group. The distribution is somewhat irregular.\nSample Size = 200: As we increase the sample size to 200, the distribution becomes smoother and starts to resemble a bell curve.\nSample Size = 500: With a sample size of 500, the bell curve shape is more pronounced, and the distribution is more concentrated around the true mean difference (0.004).\nSample Size = 1000: Finally, with a sample size of 1000, the distribution is very close to a normal distribution, tightly centered around the true mean difference.\n\nThe Central Limit Theorem states that the distribution of the sample mean (or average) will approach a normal distribution as the sample size increases, regardless of the shape of the original population distribution (in our case, the Bernoulli distribution).\nThese histograms visually demonstrate this theorem. As the sample size grows, the distribution of the average difference becomes more normal, more centered around the true population difference, and less spread out, indicating that our estimates become more precise. This is why statistical tests like the t-test, which rely on the normality assumption, become more reliable with larger sample sizes."
  }
]